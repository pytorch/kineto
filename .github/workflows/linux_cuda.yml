name: Linux CUDA build and test

on:
  push:
    branches:
      - main
  pull_request:

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.sha }}-${{ github.event_name == 'workflow_dispatch' }}
  cancel-in-progress: true

jobs:
  pr-test:
    uses: pytorch/test-infra/.github/workflows/linux_job_v2.yml@main
    with:
      job-name: linux-cuda-build-and-test
      # AWS A10G GPU instance
      runner: linux.g5.4xlarge.nvidia.gpu
      timeout: 180
      # Checkout the Kineto repo at the PR ref with submodules
      repository: ${{ github.repository }}
      ref: ${{ github.ref }}
      submodules: recursive
      gpu-arch-type: cuda
      gpu-arch-version: "12.6"
      script: |
        set -eux

        # Upgrade pip
        python -m pip install --upgrade pip
        echo "================================================="
        echo "Installed pip version: $(python -m pip --version)"
        echo "================================================="

        # Ensure cmake is minimum version Kineto requires
        conda install -y cmake>=3.22
        echo "==========================================="
        echo "Installed cmake version: $(cmake --version)"
        echo "==========================================="

        # Build libkineto (static and shared library)
        mkdir -p build_static build_shared

        pushd build_static
        cmake -DKINETO_LIBRARY_TYPE=static ../libkineto/
        make -j
        popd
        echo "========================="
        echo "Compiled static libkineto"
        echo "========================="

        pushd build_shared
        cmake -DKINETO_LIBRARY_TYPE=shared ../libkineto/
        make -j
        popd
        echo "========================="
        echo "Compiled shared libkineto"
        echo "========================="

        # Run libkineto tests
        pushd build_static
        make test
        popd
        echo "==========================="
        echo "Ran static libkineto tests"
        echo "==========================="

        # Clone PyTorch and replace its Kineto with PR version
        PYTORCH_DIR="${RUNNER_TEMP}/pytorch"
        git clone --recursive --branch viable/strict https://github.com/pytorch/pytorch.git "${PYTORCH_DIR}"
        echo "=============="
        echo "Cloned PyTorch"
        echo "=============="

        pushd "${PYTORCH_DIR}"
        rm -rf third_party/kineto
        ln -s "${GITHUB_WORKSPACE}/${GITHUB_REPOSITORY}" third_party/kineto
        echo "======================================"
        echo "Linked PR version of Kineto to PyTorch"
        echo "======================================"

        # Build PyTorch from source
        pip install -r requirements.txt
        export USE_CUDA=1
        export BUILD_TEST=1
        python setup.py develop
        echo "========================="
        echo "Built PyTorch from source"
        echo "========================="

        # Run PyTorch profiler tests
        # TODO: Dynamically add/remove tests to the exclusion list based on their
        # status on trunk instead of maintaining a hardcoded list of known failures.
        # This will prevent the list from becoming stale as tests get fixed upstream.
        python -m pytest test/profiler/ -v \
          --deselect=test/profiler/test_memory_profiler.py::TestDataFlow::test_data_flow_graph_complicated \
          --deselect=test/profiler/test_memory_profiler.py::TestMemoryProfilerE2E::test_categories_e2e_sequential_fwd_bwd \
          --deselect=test/profiler/test_memory_profiler.py::TestMemoryProfilerE2E::test_categories_e2e_simple_fwd_bwd \
          --deselect=test/profiler/test_memory_profiler.py::TestMemoryProfilerE2E::test_categories_e2e_simple_fwd_bwd_step \
          --deselect=test/profiler/test_profiler.py::TestProfiler::test_kineto \
          --deselect=test/profiler/test_profiler.py::TestProfiler::test_user_annotation \
          --deselect=test/profiler/test_profiler.py::TestExperimentalUtils::test_fuzz_symbolize \
          --deselect=test/profiler/test_profiler.py::TestExperimentalUtils::test_profiler_debug_autotuner \
          --deselect=test/profiler/test_torch_tidy.py::TestTorchTidyProfiler::test_tensorimpl_invalidation_scalar_args
        popd
        echo "=========================="
        echo "Ran PyTorch profiler tests"
        echo "=========================="
