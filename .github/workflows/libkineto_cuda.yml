name: libkineto PR Test

on:
  push:
    branches:
      - main
  pull_request:

# Use TorchBench's docker image which has all basic dependencies.
env:
  DOCKER_IMAGE: "ghcr.io/pytorch/torchbench:latest"

jobs:
  pr-test:
    strategy:
      fail-fast: false
      matrix:
        include:
          - runner: linux.g5.4xlarge.nvidia.gpu
            backend: cuda
            docker_image: "ghcr.io/pytorch/torchbench:latest"
            setup_action: pytorch/test-infra/.github/actions/setup-nvidia@main
          - runner: linux.rocm.gpu
            backend: rocm
            docker_image: "ghcr.io/pytorch/torchbench-rocm:latest"
            setup_action: pytorch/test-infra/.github/actions/setup-rocm@main
    runs-on: ${{ matrix.runner }}
    timeout-minutes: 180 # 3 hours
    steps:
      - name: Checkout Kineto
        uses: actions/checkout@v5
        with:
          path: kineto
          submodules: recursive

      - name: Pull docker image
        uses: pytorch/test-infra/.github/actions/pull-docker-image@main
        with:
          docker-image: ${{ matrix.docker_image }}

      - name: Setup GPU driver and runtime
        uses: ${{ matrix.setup_action }}

      - name: Get env vars
        run: |
          echo GITHUB_WORKFLOW   = $GITHUB_WORKFLOW
          echo HOME              = $HOME
          echo GITHUB_ACTION     = $GITHUB_ACTION
          echo GITHUB_ACTIONS    = $GITHUB_ACTIONS
          echo GITHUB_REPOSITORY = $GITHUB_REPOSITORY
          echo GITHUB_EVENT_NAME = $GITHUB_EVENT_NAME
          echo GITHUB_EVENT_PATH = $GITHUB_EVENT_PATH
          echo GITHUB_WORKSPACE  = $GITHUB_WORKSPACE
          echo GITHUB_SHA        = $GITHUB_SHA
          echo GITHUB_REF        = $GITHUB_REF

      - name: Build libkineto (static and shared library) and tests
        run: |
          container_name=$(docker run \
            ${GPU_FLAG:-} \
            --tty \
            --detach \
            --shm-size=32gb \
            -v "${PWD}/kineto:/kineto" \
            -w / \
            "${{ matrix.docker_image }}"
          )
          echo "Container name: ${container_name}"

          docker exec -t -w "/kineto" "${container_name}" bash -c "
            set -eux
            mkdir build_static
            mkdir build_shared
            pip install cmake
          "

          docker exec -t -w "/kineto/build_static" "${container_name}" bash -c "
            set -eux
            cmake -DKINETO_LIBRARY_TYPE=static ../libkineto/
            make -j
          "

          docker exec -t -w "/kineto/build_shared" "${container_name}" bash -c "
            set -eux
            cmake -DKINETO_LIBRARY_TYPE=shared ../libkineto/
            make -j
          "

          docker exec -t -w "/kineto/build_static" "${container_name}" bash -c "make test"

      - name: Clone PyTorch
        run: |
          container_name=$(docker ps -lq)
          docker exec -t -w "/" "${container_name}" bash -c "
            set -eux
            git clone --recursive https://github.com/pytorch/pytorch.git
          "

      - name: Replace PyTorch's Kineto with PR version
        run: |
          container_name=$(docker ps -lq)
          docker exec -t -w "/pytorch" "${container_name}" bash -c "
            set -eux
            rm -rf third_party/kineto
            ln -s /kineto third_party/kineto
          "

      - name: Build PyTorch from source
        run: |
          container_name=$(docker ps -lq)
          docker exec -t -w "/pytorch" "${container_name}" bash -c "
            set -eux
            pip install -r requirements.txt
            export BUILD_TEST=1
            if [ '${{ matrix.backend }}' == 'cuda' ]; then
              export USE_CUDA=1
            elif [ '${{ matrix.backend }}' == 'rocm' ]; then
              export USE_ROCM=1
            fi
            python setup.py develop
          "

      - name: Run PyTorch profiler tests
        run: |
          container_name=$(docker ps -lq)
          docker exec -t -w "/pytorch" "${container_name}" bash -c "
            set -eux
            python test/test_profiler.py -v
          "

      - name: Teardown Linux
        uses: pytorch/test-infra/.github/actions/teardown-linux@main
        if: always()

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.sha }}-${{ github.event_name == 'workflow_dispatch' }}
  cancel-in-progress: true
