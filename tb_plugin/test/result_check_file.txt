{"steps": {"columns": [{"type": "string", "name": "Step"}, {"type": "number", "name": "Kernel"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memcpy"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memset"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Runtime"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "DataLoader"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "CPU Exec"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Other"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}], "rows": [["5", 100863, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 129983us<br><b>Kernel: 100863us</b><br>Percentage: 77.6%</div>", 1948, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 129983us<br><b>Memcpy: 1948us</b><br>Percentage: 1.5%</div>", 69, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 129983us<br><b>Memset: 69us</b><br>Percentage: 0.05%</div>", 3346, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 129983us<br><b>Runtime: 3346us</b><br>Percentage: 2.57%</div>", 10023, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 129983us<br><b>DataLoader: 10023us</b><br>Percentage: 7.71%</div>", 12460, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 129983us<br><b>CPU Exec: 12460us</b><br>Percentage: 9.59%</div>", 1274, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 129983us<br><b>Other: 1274us</b><br>Percentage: 0.98%</div>"], ["6", 100576, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 158499us<br><b>Kernel: 100576us</b><br>Percentage: 63.46%</div>", 2436, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 158499us<br><b>Memcpy: 2436us</b><br>Percentage: 1.54%</div>", 69, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 158499us<br><b>Memset: 69us</b><br>Percentage: 0.04%</div>", 3144, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 158499us<br><b>Runtime: 3144us</b><br>Percentage: 1.98%</div>", 37553, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 158499us<br><b>DataLoader: 37553us</b><br>Percentage: 23.69%</div>", 13420, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 158499us<br><b>CPU Exec: 13420us</b><br>Percentage: 8.47%</div>", 1301, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 158499us<br><b>Other: 1301us</b><br>Percentage: 0.82%</div>"], ["7", 100821, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 140334us<br><b>Kernel: 100821us</b><br>Percentage: 71.84%</div>", 2111, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 140334us<br><b>Memcpy: 2111us</b><br>Percentage: 1.5%</div>", 69, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 140334us<br><b>Memset: 69us</b><br>Percentage: 0.05%</div>", 1756, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 140334us<br><b>Runtime: 1756us</b><br>Percentage: 1.25%</div>", 28965, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 140334us<br><b>DataLoader: 28965us</b><br>Percentage: 20.64%</div>", 5907, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 140334us<br><b>CPU Exec: 5907us</b><br>Percentage: 4.21%</div>", 705, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 140334us<br><b>Other: 705us</b><br>Percentage: 0.5%</div>"], ["8", 101109, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 163126us<br><b>Kernel: 101109us</b><br>Percentage: 61.98%</div>", 2078, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 163126us<br><b>Memcpy: 2078us</b><br>Percentage: 1.27%</div>", 69, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 163126us<br><b>Memset: 69us</b><br>Percentage: 0.04%</div>", 2040, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 163126us<br><b>Runtime: 2040us</b><br>Percentage: 1.25%</div>", 49998, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 163126us<br><b>DataLoader: 49998us</b><br>Percentage: 30.65%</div>", 7087, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 163126us<br><b>CPU Exec: 7087us</b><br>Percentage: 4.34%</div>", 745, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 163126us<br><b>Other: 745us</b><br>Percentage: 0.46%</div>"], ["9", 101108, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 141407us<br><b>Kernel: 101108us</b><br>Percentage: 71.5%</div>", 2072, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 141407us<br><b>Memcpy: 2072us</b><br>Percentage: 1.47%</div>", 69, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 141407us<br><b>Memset: 69us</b><br>Percentage: 0.05%</div>", 2926, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 141407us<br><b>Runtime: 2926us</b><br>Percentage: 2.07%</div>", 25338, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 141407us<br><b>DataLoader: 25338us</b><br>Percentage: 17.92%</div>", 9084, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 141407us<br><b>CPU Exec: 9084us</b><br>Percentage: 6.42%</div>", 810, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 141407us<br><b>Other: 810us</b><br>Percentage: 0.57%</div>"], ["10", 100732, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 159068us<br><b>Kernel: 100732us</b><br>Percentage: 63.33%</div>", 2089, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 159068us<br><b>Memcpy: 2089us</b><br>Percentage: 1.31%</div>", 69, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 159068us<br><b>Memset: 69us</b><br>Percentage: 0.04%</div>", 4174, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 159068us<br><b>Runtime: 4174us</b><br>Percentage: 2.62%</div>", 35514, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 159068us<br><b>DataLoader: 35514us</b><br>Percentage: 22.33%</div>", 14748, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 159068us<br><b>CPU Exec: 14748us</b><br>Percentage: 9.27%</div>", 1742, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 159068us<br><b>Other: 1742us</b><br>Percentage: 1.1%</div>"]]}, "performance": [{"name": "Average Step Time", "description": "", "value": 148736, "extra": 100, "children": [{"name": "Kernel", "description": "", "value": 100868, "extra": 67.82}, {"name": "Memcpy", "description": "", "value": 2122, "extra": 1.43}, {"name": "Memset", "description": "", "value": 69, "extra": 0.05}, {"name": "Runtime", "description": "", "value": 2898, "extra": 1.95}, {"name": "DataLoader", "description": "", "value": 31232, "extra": 21.0}, {"name": "CPU Exec", "description": "", "value": 10451, "extra": 7.03}, {"name": "Other", "description": "", "value": 1096, "extra": 0.74}]}], "recommendations": "<ul><li>This run has high time cost on input data loading. 21.0% of the step time is in DataLoader. You could try to set num_workers on DataLoader's construction and enable multi-processes on data loading. Reference: <a href =\"https://pytorch.org/docs/stable/data.html#single-and-multi-process-data-loading\" target=\"_blank\">Single- and Multi-process Data Loading</a></li></ul>", "environments": [{"title": "Number of Worker(s)", "value": "1"}, {"title": "Device Type", "value": "GPU"}]}
{"device_total_time": {"title": "Device Total Time (us)", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward", 285514], ["CudnnConvolutionBackward", 285514], ["aten::cudnn_convolution_backward_weight", 149670], ["aten::cudnn_convolution_backward_input", 135844], ["aten::cudnn_convolution", 135735], ["aten::_convolution", 135735], ["aten::convolution", 135735], ["aten::conv2d", 135735], ["aten::cudnn_batch_norm_backward", 56884], ["CudnnBatchNormBackward", 56884], ["aten::cudnn_batch_norm", 33292], ["aten::_batch_norm_impl_index", 33292], ["aten::batch_norm", 33292], ["aten::threshold_backward", 26258], ["ReluBackward1", 26258], ["aten::add_", 23357], ["aten::threshold_", 17759], ["aten::relu_", 17759], ["aten::copy_", 12734], ["aten::to", 12734], ["aten::max_pool2d_with_indices_backward", 5046], ["MaxPool2DWithIndicesBackward", 5046], ["torch::autograd::AccumulateGrad", 2915], ["aten::fill_", 2414], ["aten::zero_", 2408], ["aten::mul_", 2380], ["aten::max_pool2d_with_indices", 1341], ["aten::max_pool2d", 1341], ["aten::zeros_like", 948], ["aten::add", 325], ["aten::mm", 295], ["AddmmBackward", 295], ["aten::mean", 256], ["aten::adaptive_avg_pool2d", 256], ["aten::addmm", 201], ["aten::div", 162], ["MeanBackward1", 162], ["aten::_log_softmax_backward_data", 64], ["LogSoftmaxBackward", 64], ["aten::_log_softmax", 60], ["aten::log_softmax", 60], ["aten::nll_loss_forward", 20], ["aten::nll_loss", 20], ["aten::nll_loss_backward", 18], ["NllLossBackward", 18], ["aten::ones_like", 6]]}, "device_self_time": {"title": "Device Self Time (us)", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward_weight", 149670], ["aten::cudnn_convolution_backward_input", 135844], ["aten::cudnn_convolution", 135735], ["aten::cudnn_batch_norm_backward", 56884], ["aten::cudnn_batch_norm", 33292], ["aten::threshold_backward", 26258], ["aten::add_", 23357], ["aten::threshold_", 17759], ["aten::copy_", 12734], ["aten::max_pool2d_with_indices_backward", 4098], ["aten::fill_", 2414], ["aten::mul_", 2380], ["aten::max_pool2d_with_indices", 1341], ["aten::add", 325], ["aten::mm", 295], ["aten::mean", 256], ["aten::addmm", 201], ["aten::div", 162], ["aten::_log_softmax_backward_data", 64], ["aten::_log_softmax", 60], ["aten::nll_loss_forward", 20], ["aten::nll_loss_backward", 18]]}, "host_total_time": {"title": "Host Total Time (us)", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::add_", 96814], ["CudnnConvolutionBackward", 90857], ["aten::cudnn_convolution_backward", 87104], ["aten::conv2d", 61610], ["aten::copy_", 60140], ["aten::convolution", 57644], ["aten::batch_norm", 55154], ["aten::_convolution", 53789], ["aten::_batch_norm_impl_index", 51122], ["aten::cudnn_convolution", 49275], ["aten::cudnn_batch_norm", 47638], ["aten::to", 46057], ["aten::cudnn_convolution_backward_weight", 39006], ["aten::cudnn_convolution_backward_input", 38583], ["aten::mul_", 36843], ["aten::zero_", 36160], ["torch::autograd::AccumulateGrad", 34208], ["aten::empty", 33098], ["aten::stack", 33058], ["CudnnBatchNormBackward", 32186], ["aten::cat", 31169], ["aten::_cat", 30970], ["aten::div", 30671], ["aten::cudnn_batch_norm_backward", 27883], ["aten::contiguous", 24479], ["aten::fill_", 21081], ["aten::relu_", 16620], ["ReluBackward1", 15142], ["aten::add", 14945], ["aten::threshold_backward", 12601], ["aten::threshold_", 9128], ["aten::empty_like", 8255], ["aten::view", 4811], ["aten::resize_", 3415], ["aten::permute", 3161], ["aten::set_", 2994], ["aten::empty_strided", 1725], ["AddmmBackward", 1462], ["aten::unsqueeze", 1293], ["aten::addmm", 1274], ["aten::as_strided", 948], ["aten::mm", 847], ["MaxPool2DWithIndicesBackward", 763], ["aten::max_pool2d", 732], ["NllLossBackward", 719], ["aten::max_pool2d_with_indices_backward", 686], ["aten::t", 664], ["aten::zeros", 651], ["aten::max_pool2d_with_indices", 644], ["MeanBackward1", 606], ["aten::nll_loss_backward", 590], ["aten::adaptive_avg_pool2d", 566], ["aten::log_softmax", 527], ["aten::nll_loss", 500], ["aten::mean", 484], ["LogSoftmaxBackward", 451], ["aten::_log_softmax", 447], ["aten::nll_loss_forward", 425], ["aten::ones_like", 410], ["aten::_log_softmax_backward_data", 357], ["aten::zeros_like", 339], ["aten::transpose", 309], ["AddBackward0", 309], ["aten::reshape", 228], ["aten::flatten", 206], ["aten::expand", 141], ["TBackward", 140], ["ViewBackward", 121], ["aten::narrow", 87], ["aten::detach_", 64], ["aten::resize_as_", 54], ["aten::slice", 52], ["aten::conj", 46], ["detach_", 33]]}, "host_self_time": {"title": "Host Self Time (us)", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::add_", 64646], ["aten::copy_", 45838], ["aten::cudnn_convolution", 34235], ["aten::empty", 33098], ["aten::_cat", 30756], ["aten::cudnn_batch_norm", 26997], ["aten::div", 25915], ["aten::cudnn_convolution_backward_input", 25552], ["aten::mul_", 24290], ["aten::cudnn_convolution_backward_weight", 22973], ["aten::cudnn_batch_norm_backward", 15840], ["aten::zero_", 15259], ["aten::add", 9687], ["aten::cudnn_convolution_backward", 9515], ["aten::fill_", 9102], ["aten::relu_", 7492], ["aten::threshold_backward", 7183], ["torch::autograd::AccumulateGrad", 6798], ["aten::view", 4811], ["aten::to", 4680], ["aten::_convolution", 4514], ["aten::empty_like", 4430], ["CudnnBatchNormBackward", 4303], ["aten::threshold_", 4261], ["aten::batch_norm", 4032], ["aten::conv2d", 3966], ["aten::convolution", 3855], ["CudnnConvolutionBackward", 3753], ["aten::_batch_norm_impl_index", 3484], ["aten::resize_", 3415], ["aten::set_", 2994], ["aten::permute", 2703], ["ReluBackward1", 2541], ["aten::contiguous", 2069], ["aten::empty_strided", 1725], ["aten::as_strided", 948], ["aten::unsqueeze", 925], ["aten::addmm", 699], ["aten::stack", 596], ["aten::zeros", 463], ["aten::mm", 439], ["aten::max_pool2d_with_indices", 367], ["aten::t", 355], ["aten::nll_loss_forward", 310], ["AddBackward0", 309], ["aten::mean", 280], ["aten::nll_loss_backward", 278], ["aten::transpose", 226], ["aten::_log_softmax", 225], ["aten::max_pool2d_with_indices_backward", 211], ["aten::cat", 199], ["AddmmBackward", 195], ["aten::_log_softmax_backward_data", 153], ["NllLossBackward", 129], ["aten::expand", 113], ["MeanBackward1", 103], ["aten::ones_like", 100], ["LogSoftmaxBackward", 94], ["aten::max_pool2d", 88], ["aten::adaptive_avg_pool2d", 82], ["aten::log_softmax", 80], ["MaxPool2DWithIndicesBackward", 77], ["aten::nll_loss", 75], ["aten::reshape", 71], ["aten::flatten", 65], ["aten::zeros_like", 53], ["aten::conj", 46], ["aten::resize_as_", 44], ["aten::slice", 41], ["aten::narrow", 35], ["ViewBackward", 34], ["detach_", 33], ["aten::detach_", 31], ["TBackward", 29]]}}
{"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Device Self Duration (us)"}, {"type": "number", "name": "Device Total Duration (us)"}, {"type": "number", "name": "Host Self Duration (us)"}, {"type": "number", "name": "Host Total Duration (us)"}], "rows": [["aten::cudnn_convolution_backward_weight", 318, 149670, 149670, 22973, 39006], ["aten::cudnn_convolution_backward_input", 312, 135844, 135844, 25552, 38583], ["aten::cudnn_convolution", 318, 135735, 135735, 34235, 49275], ["aten::cudnn_batch_norm_backward", 318, 56884, 56884, 15840, 27883], ["aten::cudnn_batch_norm", 318, 33292, 33292, 26997, 47638], ["aten::threshold_backward", 294, 26258, 26258, 7183, 12601], ["aten::add_", 2994, 23357, 23357, 64646, 96814], ["aten::threshold_", 294, 17759, 17759, 4261, 9128], ["aten::copy_", 588, 12734, 12734, 45838, 60140], ["aten::max_pool2d_with_indices_backward", 6, 4098, 5046, 211, 686], ["aten::fill_", 978, 2414, 2414, 9102, 21081], ["aten::mul_", 966, 2380, 2380, 24290, 36843], ["aten::max_pool2d_with_indices", 6, 1341, 1341, 367, 644], ["aten::add", 318, 325, 325, 9687, 14945], ["aten::mm", 12, 295, 295, 439, 847], ["aten::mean", 6, 256, 256, 280, 484], ["aten::addmm", 6, 201, 201, 699, 1274], ["aten::div", 198, 162, 162, 25915, 30671], ["aten::_log_softmax_backward_data", 6, 64, 64, 153, 357], ["aten::_log_softmax", 6, 60, 60, 225, 447], ["aten::nll_loss_forward", 6, 20, 20, 310, 425], ["aten::nll_loss_backward", 6, 18, 18, 278, 590], ["aten::empty", 5748, 0, 0, 33098, 33098], ["aten::zero_", 996, 0, 2408, 15259, 36160], ["aten::zeros", 24, 0, 0, 463, 651], ["aten::set_", 192, 0, 0, 2994, 2994], ["aten::view", 840, 0, 0, 4811, 4811], ["aten::as_strided", 432, 0, 0, 948, 948], ["aten::permute", 192, 0, 0, 2703, 3161], ["aten::empty_like", 534, 0, 0, 4430, 8255], ["aten::contiguous", 192, 0, 0, 2069, 24479], ["aten::empty_strided", 402, 0, 0, 1725, 1725], ["aten::to", 408, 0, 12734, 4680, 46057], ["aten::unsqueeze", 192, 0, 0, 925, 1293], ["aten::resize_", 1926, 0, 0, 3415, 3415], ["aten::slice", 6, 0, 0, 41, 52], ["aten::narrow", 6, 0, 0, 35, 87], ["aten::_cat", 6, 0, 0, 30756, 30970], ["aten::cat", 6, 0, 0, 199, 31169], ["aten::stack", 6, 0, 0, 596, 33058], ["detach_", 6, 0, 0, 33, 33], ["aten::detach_", 6, 0, 0, 31, 64], ["aten::_convolution", 318, 0, 135735, 4514, 53789], ["aten::convolution", 318, 0, 135735, 3855, 57644], ["aten::conv2d", 318, 0, 135735, 3966, 61610], ["aten::_batch_norm_impl_index", 318, 0, 33292, 3484, 51122], ["aten::batch_norm", 318, 0, 33292, 4032, 55154], ["aten::relu_", 294, 0, 17759, 7492, 16620], ["aten::max_pool2d", 6, 0, 1341, 88, 732], ["aten::adaptive_avg_pool2d", 6, 0, 256, 82, 566], ["aten::reshape", 12, 0, 0, 71, 228], ["aten::flatten", 6, 0, 0, 65, 206], ["aten::transpose", 30, 0, 0, 226, 309], ["aten::t", 30, 0, 0, 355, 664], ["aten::expand", 12, 0, 0, 113, 141], ["aten::log_softmax", 6, 0, 60, 80, 527], ["aten::nll_loss", 6, 0, 20, 75, 500], ["aten::ones_like", 6, 0, 6, 100, 410], ["NllLossBackward", 6, 0, 18, 129, 719], ["LogSoftmaxBackward", 6, 0, 64, 94, 451], ["aten::conj", 12, 0, 0, 46, 46], ["AddmmBackward", 6, 0, 295, 195, 1462], ["torch::autograd::AccumulateGrad", 966, 0, 2915, 6798, 34208], ["TBackward", 6, 0, 0, 29, 140], ["ViewBackward", 6, 0, 0, 34, 121], ["MeanBackward1", 6, 0, 162, 103, 606], ["ReluBackward1", 294, 0, 26258, 2541, 15142], ["AddBackward0", 96, 0, 0, 309, 309], ["CudnnBatchNormBackward", 318, 0, 56884, 4303, 32186], ["aten::cudnn_convolution_backward", 318, 0, 285514, 9515, 87104], ["CudnnConvolutionBackward", 318, 0, 285514, 3753, 90857], ["aten::zeros_like", 6, 0, 948, 53, 339], ["aten::resize_as_", 6, 0, 0, 44, 54], ["MaxPool2DWithIndicesBackward", 6, 0, 5046, 77, 763]]}}
{"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Total Duration (us)"}, {"type": "number", "name": "Mean Duration (us)"}, {"type": "number", "name": "Max Duration (us)"}, {"type": "number", "name": "Min Duration (us)"}], "rows": [["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", 167, 86835, 520, 1084, 330], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", 287, 61395, 214, 799, 43], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 104, 53577, 515, 815, 393], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", 609, 47050, 77, 364, 6], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", 3489, 41190, 12, 364, 1], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 90, 40341, 448, 753, 381], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 60, 28063, 468, 851, 361], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", 72, 27624, 384, 667, 354], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", 34, 27184, 800, 885, 664], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", 150, 26234, 175, 426, 50], ["volta_sgemm_128x64_nt", 126, 23737, 188, 206, 155], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", 48, 21753, 453, 705, 328], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", 39, 14259, 366, 370, 361], ["volta_sgemm_128x64_nn", 60, 11407, 190, 207, 156], ["volta_scudnn_128x64_stridedB_interior_nn_v1", 34, 10904, 321, 525, 263], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 12, 8816, 735, 784, 660], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 14, 8346, 596, 990, 207], ["volta_scudnn_128x64_relu_interior_nn_v1", 24, 7210, 300, 311, 295], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", 168, 7058, 42, 87, 14], ["volta_scudnn_128x128_stridedB_interior_nn_v1", 21, 5717, 272, 275, 269], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", 167, 5482, 33, 158, 6], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 12, 5341, 445, 449, 442], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 7, 5298, 757, 780, 732], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", 123, 5250, 43, 68, 19], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 6, 4895, 816, 822, 809], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", 7, 4781, 683, 684, 682], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 123, 4765, 39, 63, 17], ["volta_scudnn_128x128_stridedB_medium_nn_v1", 14, 4312, 308, 325, 299], ["volta_scudnn_128x64_relu_medium_nn_v1", 6, 3829, 638, 641, 637], ["volta_scudnn_128x128_stridedB_small_nn_v1", 7, 3709, 530, 533, 527], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 6, 3533, 589, 659, 573], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", 6, 3532, 589, 672, 569], ["volta_scudnn_128x64_relu_small_nn_v1", 12, 3395, 283, 296, 270], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", 1127, 2779, 2, 24, 1], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", 123, 2617, 21, 66, 4], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 63, 2602, 41, 60, 21], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", 979, 2572, 3, 158, 0], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", 63, 2449, 39, 61, 16], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", 54, 2283, 42, 74, 19], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", 12, 1699, 142, 184, 98], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", 6, 1341, 224, 224, 223], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", 63, 1306, 21, 63, 4], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 6, 848, 141, 142, 140], ["volta_scudnn_128x64_stridedB_small_nn_v1", 7, 666, 95, 96, 94], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", 131, 330, 3, 4, 2], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", 318, 325, 1, 2, 1], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", 6, 256, 43, 43, 42], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", 154, 198, 1, 2, 1], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", 154, 174, 1, 2, 1], ["volta_sgemm_64x32_sliced1x4_nn", 6, 166, 28, 28, 27], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", 6, 162, 27, 27, 27], ["volta_sgemm_64x32_sliced1x4_tn", 6, 145, 24, 25, 24], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", 39, 135, 3, 5, 3], ["volta_sgemm_128x32_nt", 6, 117, 20, 20, 19], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", 83, 90, 1, 2, 1], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", 6, 64, 11, 11, 10], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", 6, 60, 10, 10, 10], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", 6, 48, 8, 8, 8], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", 12, 35, 3, 4, 2], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", 6, 33, 6, 6, 5], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", 6, 20, 3, 4, 3], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", 6, 12, 2, 2, 2]]}}
{"total": {"columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", 86835.0], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", 61395.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 53577.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", 47050.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", 41190.0], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 40341.0], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 28063.0], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", 27624.0], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", 27184.0], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", 26234.0], ["volta_sgemm_128x64_nt", 23737.0], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", 21753.0], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", 14259.0], ["volta_sgemm_128x64_nn", 11407.0], ["volta_scudnn_128x64_stridedB_interior_nn_v1", 10904.0], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 8816.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 8346.0], ["volta_scudnn_128x64_relu_interior_nn_v1", 7210.0], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", 7058.0], ["volta_scudnn_128x128_stridedB_interior_nn_v1", 5717.0], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", 5482.0], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 5341.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 5298.0], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", 5250.0], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 4895.0], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", 4781.0], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 4765.0], ["volta_scudnn_128x128_stridedB_medium_nn_v1", 4312.0], ["volta_scudnn_128x64_relu_medium_nn_v1", 3829.0], ["volta_scudnn_128x128_stridedB_small_nn_v1", 3709.0], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 3533.0], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", 3532.0], ["volta_scudnn_128x64_relu_small_nn_v1", 3395.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", 2779.0], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", 2617.0], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 2602.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", 2572.0], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", 2449.0], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", 2283.0], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", 1699.0], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", 1341.0], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", 1306.0], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 848.0], ["volta_scudnn_128x64_stridedB_small_nn_v1", 666.0], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", 330.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", 325.0], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", 256.0], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", 198.0], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", 174.0], ["volta_sgemm_64x32_sliced1x4_nn", 166.0], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", 162.0], ["volta_sgemm_64x32_sliced1x4_tn", 145.0], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", 135.0], ["volta_sgemm_128x32_nt", 117.0], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", 90.0], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", 64.0], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", 60.0], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", 48.0], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", 35.0], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", 33.0], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", 20.0], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", 12.0]]}}
{"steps": {"columns": [{"type": "string", "name": "Step"}, {"type": "number", "name": "Kernel"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memcpy"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memset"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Runtime"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "DataLoader"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "CPU Exec"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Other"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}], "rows": [["5", 101214, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 118439us<br><b>Kernel: 101214us</b><br>Percentage: 85.46%</div>", 3344, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 118439us<br><b>Memcpy: 3344us</b><br>Percentage: 2.82%</div>", 54, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 118439us<br><b>Memset: 54us</b><br>Percentage: 0.05%</div>", 2996, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 118439us<br><b>Runtime: 2996us</b><br>Percentage: 2.53%</div>", 3, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 118439us<br><b>DataLoader: 3us</b><br>Percentage: 0.0%</div>", 10088, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 118439us<br><b>CPU Exec: 10088us</b><br>Percentage: 8.52%</div>", 740, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 118439us<br><b>Other: 740us</b><br>Percentage: 0.62%</div>"], ["6", 101100, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 116360us<br><b>Kernel: 101100us</b><br>Percentage: 86.89%</div>", 3239, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 116360us<br><b>Memcpy: 3239us</b><br>Percentage: 2.78%</div>", 54, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 116360us<br><b>Memset: 54us</b><br>Percentage: 0.05%</div>", 2811, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 116360us<br><b>Runtime: 2811us</b><br>Percentage: 2.42%</div>", 15, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 116360us<br><b>DataLoader: 15us</b><br>Percentage: 0.01%</div>", 8391, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 116360us<br><b>CPU Exec: 8391us</b><br>Percentage: 7.21%</div>", 750, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 116360us<br><b>Other: 750us</b><br>Percentage: 0.64%</div>"], ["7", 101159, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 114583us<br><b>Kernel: 101159us</b><br>Percentage: 88.28%</div>", 3218, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 114583us<br><b>Memcpy: 3218us</b><br>Percentage: 2.81%</div>", 54, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 114583us<br><b>Memset: 54us</b><br>Percentage: 0.05%</div>", 2584, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 114583us<br><b>Runtime: 2584us</b><br>Percentage: 2.26%</div>", 23, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 114583us<br><b>DataLoader: 23us</b><br>Percentage: 0.02%</div>", 6908, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 114583us<br><b>CPU Exec: 6908us</b><br>Percentage: 6.03%</div>", 637, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 114583us<br><b>Other: 637us</b><br>Percentage: 0.56%</div>"], ["8", 101317, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 119884us<br><b>Kernel: 101317us</b><br>Percentage: 84.51%</div>", 3251, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 119884us<br><b>Memcpy: 3251us</b><br>Percentage: 2.71%</div>", 54, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 119884us<br><b>Memset: 54us</b><br>Percentage: 0.05%</div>", 2929, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 119884us<br><b>Runtime: 2929us</b><br>Percentage: 2.44%</div>", 13, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 119884us<br><b>DataLoader: 13us</b><br>Percentage: 0.01%</div>", 11610, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 119884us<br><b>CPU Exec: 11610us</b><br>Percentage: 9.68%</div>", 710, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 119884us<br><b>Other: 710us</b><br>Percentage: 0.59%</div>"], ["9", 101022, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 117173us<br><b>Kernel: 101022us</b><br>Percentage: 86.22%</div>", 3308, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 117173us<br><b>Memcpy: 3308us</b><br>Percentage: 2.82%</div>", 54, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 117173us<br><b>Memset: 54us</b><br>Percentage: 0.05%</div>", 3002, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 117173us<br><b>Runtime: 3002us</b><br>Percentage: 2.56%</div>", 16, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 117173us<br><b>DataLoader: 16us</b><br>Percentage: 0.01%</div>", 9021, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 117173us<br><b>CPU Exec: 9021us</b><br>Percentage: 7.7%</div>", 750, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 117173us<br><b>Other: 750us</b><br>Percentage: 0.64%</div>"], ["10", 101236, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 139414us<br><b>Kernel: 101236us</b><br>Percentage: 72.62%</div>", 3361, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 139414us<br><b>Memcpy: 3361us</b><br>Percentage: 2.41%</div>", 54, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 139414us<br><b>Memset: 54us</b><br>Percentage: 0.04%</div>", 2192, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 139414us<br><b>Runtime: 2192us</b><br>Percentage: 1.57%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 139414us<br><b>DataLoader: 0us</b><br>Percentage: 0.0%</div>", 8527, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 139414us<br><b>CPU Exec: 8527us</b><br>Percentage: 6.12%</div>", 24044, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 139414us<br><b>Other: 24044us</b><br>Percentage: 17.25%</div>"]]}, "performance": [{"name": "Average Step Time", "description": "", "value": 120976, "extra": 100, "children": [{"name": "Kernel", "description": "", "value": 101175, "extra": 83.63}, {"name": "Memcpy", "description": "", "value": 3287, "extra": 2.72}, {"name": "Memset", "description": "", "value": 54, "extra": 0.04}, {"name": "Runtime", "description": "", "value": 2752, "extra": 2.28}, {"name": "DataLoader", "description": "", "value": 12, "extra": 0.01}, {"name": "CPU Exec", "description": "", "value": 9091, "extra": 7.51}, {"name": "Other", "description": "", "value": 4605, "extra": 3.81}]}], "recommendations": "<ul><li>N/A</li></ul>", "environments": [{"title": "Number of Worker(s)", "value": "1"}, {"title": "Device Type", "value": "GPU"}]}
{"device_total_time": {"title": "Device Total Time (us)", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward", 288342], ["CudnnConvolutionBackward", 288342], ["aten::cudnn_convolution_backward_weight", 151977], ["aten::cudnn_convolution_backward_input", 136365], ["aten::cudnn_convolution", 134544], ["aten::_convolution", 134544], ["aten::convolution", 134544], ["aten::conv2d", 134544], ["aten::cudnn_batch_norm_backward", 56960], ["CudnnBatchNormBackward", 56960], ["aten::cudnn_batch_norm", 33334], ["aten::_batch_norm_impl_index", 33334], ["aten::batch_norm", 33334], ["aten::threshold_backward", 26280], ["ReluBackward1", 26280], ["aten::add_", 23354], ["aten::to", 19721], ["aten::copy_", 19721], ["aten::threshold_", 17770], ["aten::relu_", 17770], ["aten::max_pool2d_with_indices_backward", 5053], ["MaxPool2DWithIndicesBackward", 5053], ["torch::autograd::AccumulateGrad", 2918], ["aten::fill_", 2376], ["aten::mul_", 2376], ["aten::zero_", 2370], ["aten::max_pool2d_with_indices", 1341], ["aten::max_pool2d", 1341], ["aten::zeros_like", 948], ["aten::add", 327], ["aten::mm", 288], ["AddmmBackward", 288], ["aten::mean", 258], ["aten::adaptive_avg_pool2d", 258], ["aten::addmm", 204], ["aten::div", 161], ["MeanBackward1", 161], ["aten::_log_softmax_backward_data", 63], ["LogSoftmaxBackward", 63], ["aten::_log_softmax", 60], ["aten::log_softmax", 60], ["aten::nll_loss_forward", 21], ["aten::nll_loss", 21], ["aten::nll_loss_backward", 19], ["NllLossBackward", 19], ["aten::ones_like", 6]]}, "device_self_time": {"title": "Device Self Time (us)", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward_weight", 151977], ["aten::cudnn_convolution_backward_input", 136365], ["aten::cudnn_convolution", 134544], ["aten::cudnn_batch_norm_backward", 56960], ["aten::cudnn_batch_norm", 33334], ["aten::threshold_backward", 26280], ["aten::add_", 23354], ["aten::copy_", 19721], ["aten::threshold_", 17770], ["aten::max_pool2d_with_indices_backward", 4105], ["aten::fill_", 2376], ["aten::mul_", 2376], ["aten::max_pool2d_with_indices", 1341], ["aten::add", 327], ["aten::mm", 288], ["aten::mean", 258], ["aten::addmm", 204], ["aten::div", 161], ["aten::_log_softmax_backward_data", 63], ["aten::_log_softmax", 60], ["aten::nll_loss_forward", 21], ["aten::nll_loss_backward", 19]]}, "host_total_time": {"title": "Host Total Time (us)", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::to", 95877], ["aten::copy_", 95330], ["CudnnConvolutionBackward", 89870], ["aten::add_", 88364], ["aten::cudnn_convolution_backward", 85929], ["aten::conv2d", 60800], ["aten::convolution", 56995], ["aten::batch_norm", 53643], ["aten::_convolution", 53318], ["aten::_batch_norm_impl_index", 50036], ["aten::cudnn_convolution", 48860], ["aten::cudnn_batch_norm", 46680], ["torch::autograd::AccumulateGrad", 43241], ["aten::cudnn_convolution_backward_input", 39025], ["aten::cudnn_convolution_backward_weight", 37464], ["CudnnBatchNormBackward", 34153], ["aten::mul_", 32585], ["aten::zero_", 32441], ["aten::cudnn_batch_norm_backward", 29705], ["aten::empty", 29598], ["aten::fill_", 19488], ["aten::relu_", 16391], ["ReluBackward1", 15546], ["aten::add", 14077], ["aten::threshold_backward", 13019], ["aten::threshold_", 8921], ["aten::empty_like", 6343], ["aten::resize_", 3854], ["aten::view", 2824], ["AddmmBackward", 1508], ["aten::addmm", 1219], ["aten::mm", 857], ["MaxPool2DWithIndicesBackward", 779], ["NllLossBackward", 737], ["aten::t", 714], ["aten::max_pool2d", 709], ["aten::max_pool2d_with_indices_backward", 699], ["aten::zeros", 625], ["aten::max_pool2d_with_indices", 622], ["MeanBackward1", 615], ["aten::nll_loss_backward", 604], ["aten::adaptive_avg_pool2d", 530], ["aten::log_softmax", 513], ["aten::nll_loss", 504], ["LogSoftmaxBackward", 454], ["aten::mean", 449], ["aten::_log_softmax", 434], ["aten::nll_loss_forward", 430], ["aten::div", 426], ["aten::_log_softmax_backward_data", 383], ["aten::ones_like", 381], ["AddBackward0", 337], ["aten::transpose", 331], ["aten::zeros_like", 331], ["aten::empty_strided", 319], ["aten::reshape", 223], ["aten::flatten", 187], ["TBackward", 174], ["aten::expand", 150], ["ViewBackward", 130], ["aten::as_strided", 128], ["aten::set_", 118], ["aten::detach_", 95], ["aten::resize_as_", 60], ["aten::conj", 53], ["detach_", 32]]}, "host_self_time": {"title": "Host Self Time (us)", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::add_", 55210], ["aten::cudnn_convolution", 34694], ["aten::empty", 29598], ["aten::cudnn_batch_norm", 26054], ["aten::cudnn_convolution_backward_input", 25909], ["aten::cudnn_convolution_backward_weight", 22068], ["aten::mul_", 20698], ["aten::cudnn_batch_norm_backward", 17176], ["aten::zero_", 13103], ["torch::autograd::AccumulateGrad", 12619], ["aten::cudnn_convolution_backward", 9440], ["aten::add", 8964], ["aten::fill_", 8708], ["aten::relu_", 7470], ["aten::threshold_backward", 7358], ["aten::_convolution", 4458], ["CudnnBatchNormBackward", 4448], ["aten::threshold_", 4042], ["CudnnConvolutionBackward", 3941], ["aten::resize_", 3854], ["aten::conv2d", 3805], ["aten::convolution", 3677], ["aten::batch_norm", 3607], ["aten::empty_like", 3452], ["aten::_batch_norm_impl_index", 3356], ["aten::view", 2824], ["ReluBackward1", 2527], ["aten::addmm", 690], ["aten::zeros", 465], ["aten::mm", 460], ["aten::copy_", 426], ["aten::t", 383], ["aten::max_pool2d_with_indices", 363], ["AddBackward0", 337], ["aten::empty_strided", 319], ["aten::nll_loss_forward", 317], ["aten::to", 300], ["aten::mean", 283], ["aten::nll_loss_backward", 279], ["aten::div", 265], ["aten::transpose", 233], ["aten::_log_softmax", 224], ["aten::max_pool2d_with_indices_backward", 223], ["AddmmBackward", 213], ["aten::_log_softmax_backward_data", 160], ["NllLossBackward", 133], ["aten::as_strided", 128], ["aten::expand", 120], ["aten::set_", 118], ["aten::max_pool2d", 87], ["MeanBackward1", 87], ["aten::ones_like", 85], ["aten::adaptive_avg_pool2d", 81], ["MaxPool2DWithIndicesBackward", 80], ["aten::log_softmax", 79], ["aten::nll_loss", 74], ["LogSoftmaxBackward", 71], ["aten::reshape", 70], ["aten::detach_", 63], ["aten::flatten", 59], ["aten::zeros_like", 54], ["aten::conj", 53], ["aten::resize_as_", 49], ["TBackward", 43], ["ViewBackward", 35], ["detach_", 32]]}}
{"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Device Self Duration (us)"}, {"type": "number", "name": "Device Total Duration (us)"}, {"type": "number", "name": "Host Self Duration (us)"}, {"type": "number", "name": "Host Total Duration (us)"}], "rows": [["aten::cudnn_convolution_backward_weight", 318, 151977, 151977, 22068, 37464], ["aten::cudnn_convolution_backward_input", 312, 136365, 136365, 25909, 39025], ["aten::cudnn_convolution", 318, 134544, 134544, 34694, 48860], ["aten::cudnn_batch_norm_backward", 318, 56960, 56960, 17176, 29705], ["aten::cudnn_batch_norm", 318, 33334, 33334, 26054, 46680], ["aten::threshold_backward", 294, 26280, 26280, 7358, 13019], ["aten::add_", 2994, 23354, 23354, 55210, 88364], ["aten::copy_", 12, 19721, 19721, 426, 95330], ["aten::threshold_", 294, 17770, 17770, 4042, 8921], ["aten::max_pool2d_with_indices_backward", 6, 4105, 5053, 223, 699], ["aten::fill_", 978, 2376, 2376, 8708, 19488], ["aten::mul_", 966, 2376, 2376, 20698, 32585], ["aten::max_pool2d_with_indices", 6, 1341, 1341, 363, 622], ["aten::add", 318, 327, 327, 8964, 14077], ["aten::mm", 12, 288, 288, 460, 857], ["aten::mean", 6, 258, 258, 283, 449], ["aten::addmm", 6, 204, 204, 690, 1219], ["aten::div", 6, 161, 161, 265, 426], ["aten::_log_softmax_backward_data", 6, 63, 63, 160, 383], ["aten::_log_softmax", 6, 60, 60, 224, 434], ["aten::nll_loss_forward", 6, 21, 21, 317, 430], ["aten::nll_loss_backward", 6, 19, 19, 279, 604], ["aten::empty", 5172, 0, 0, 29598, 29598], ["aten::zero_", 996, 0, 2370, 13103, 32441], ["aten::zeros", 24, 0, 0, 465, 625], ["aten::to", 30, 0, 19721, 300, 95877], ["detach_", 12, 0, 0, 32, 32], ["aten::detach_", 12, 0, 0, 63, 95], ["aten::set_", 12, 0, 0, 118, 118], ["aten::empty_strided", 18, 0, 0, 319, 319], ["aten::resize_", 1920, 0, 0, 3854, 3854], ["aten::_convolution", 318, 0, 134544, 4458, 53318], ["aten::convolution", 318, 0, 134544, 3677, 56995], ["aten::conv2d", 318, 0, 134544, 3805, 60800], ["aten::empty_like", 342, 0, 0, 3452, 6343], ["aten::view", 648, 0, 0, 2824, 2824], ["aten::_batch_norm_impl_index", 318, 0, 33334, 3356, 50036], ["aten::batch_norm", 318, 0, 33334, 3607, 53643], ["aten::relu_", 294, 0, 17770, 7470, 16391], ["aten::max_pool2d", 6, 0, 1341, 87, 709], ["aten::adaptive_avg_pool2d", 6, 0, 258, 81, 530], ["aten::reshape", 12, 0, 0, 70, 223], ["aten::flatten", 6, 0, 0, 59, 187], ["aten::as_strided", 42, 0, 0, 128, 128], ["aten::transpose", 30, 0, 0, 233, 331], ["aten::t", 30, 0, 0, 383, 714], ["aten::expand", 12, 0, 0, 120, 150], ["aten::log_softmax", 6, 0, 60, 79, 513], ["aten::nll_loss", 6, 0, 21, 74, 504], ["aten::ones_like", 6, 0, 6, 85, 381], ["NllLossBackward", 6, 0, 19, 133, 737], ["LogSoftmaxBackward", 6, 0, 63, 71, 454], ["aten::conj", 12, 0, 0, 53, 53], ["AddmmBackward", 6, 0, 288, 213, 1508], ["torch::autograd::AccumulateGrad", 966, 0, 2918, 12619, 43241], ["TBackward", 6, 0, 0, 43, 174], ["ViewBackward", 6, 0, 0, 35, 130], ["MeanBackward1", 6, 0, 161, 87, 615], ["ReluBackward1", 294, 0, 26280, 2527, 15546], ["AddBackward0", 96, 0, 0, 337, 337], ["CudnnBatchNormBackward", 318, 0, 56960, 4448, 34153], ["aten::cudnn_convolution_backward", 318, 0, 288342, 9440, 85929], ["CudnnConvolutionBackward", 318, 0, 288342, 3941, 89870], ["aten::zeros_like", 6, 0, 948, 54, 331], ["aten::resize_as_", 6, 0, 0, 49, 60], ["MaxPool2DWithIndicesBackward", 6, 0, 5053, 80, 779]]}}
{"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Total Duration (us)"}, {"type": "number", "name": "Mean Duration (us)"}, {"type": "number", "name": "Max Duration (us)"}, {"type": "number", "name": "Min Duration (us)"}], "rows": [["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", 178, 90214, 507, 1092, 154], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 179, 85427, 477, 814, 381], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", 292, 62347, 214, 802, 43], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", 613, 47476, 77, 364, 6], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", 3506, 41486, 12, 364, 1], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 84, 36210, 431, 753, 384], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 66, 32761, 496, 854, 362], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", 150, 26289, 175, 433, 50], ["volta_sgemm_128x64_nt", 126, 23803, 189, 205, 156], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", 49, 22477, 459, 705, 329], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 21, 18728, 892, 913, 881], ["volta_sgemm_128x64_nn", 78, 14530, 186, 207, 157], ["volta_scudnn_128x64_stridedB_interior_nn_v1", 35, 11515, 329, 528, 260], ["volta_scudnn_128x64_relu_interior_nn_v1", 30, 10280, 343, 530, 295], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 14, 8372, 598, 993, 207], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", 21, 7728, 368, 377, 365], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", 141, 7213, 51, 115, 20], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 141, 7133, 51, 143, 17], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", 168, 7045, 42, 87, 14], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", 178, 5920, 33, 158, 6], ["volta_scudnn_128x128_stridedB_interior_nn_v1", 21, 5763, 274, 294, 269], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 12, 5352, 446, 449, 443], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 7, 5335, 762, 781, 744], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 6, 4882, 814, 817, 811], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", 7, 4795, 685, 690, 683], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", 7, 4662, 666, 669, 658], ["volta_scudnn_128x128_stridedB_medium_nn_v1", 14, 4373, 312, 327, 297], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 6, 4023, 670, 676, 663], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", 6, 4007, 668, 672, 664], ["volta_scudnn_128x64_relu_medium_nn_v1", 6, 3850, 642, 644, 638], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", 6, 3731, 622, 672, 571], ["volta_scudnn_128x128_stridedB_small_nn_v1", 7, 3726, 532, 542, 526], ["volta_scudnn_128x64_relu_small_nn_v1", 12, 3427, 286, 295, 272], ["volta_scudnn_128x128_relu_interior_nn_v1", 6, 3340, 557, 562, 551], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", 1127, 2771, 2, 24, 1], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", 141, 2699, 19, 66, 3], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 63, 2540, 40, 60, 20], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", 979, 2534, 3, 158, 0], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", 63, 2479, 39, 60, 18], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", 54, 2313, 43, 74, 19], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", 6, 1341, 224, 224, 223], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", 63, 1320, 21, 65, 4], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 6, 864, 144, 147, 142], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", 6, 601, 100, 101, 99], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", 137, 352, 3, 6, 2], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", 318, 327, 1, 2, 1], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", 6, 258, 43, 43, 43], ["volta_sgemm_64x32_sliced1x4_nn", 6, 161, 27, 27, 26], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", 6, 161, 27, 27, 26], ["volta_sgemm_64x32_sliced1x4_tn", 6, 144, 24, 24, 24], ["volta_sgemm_128x32_nt", 6, 115, 19, 20, 19], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", 62, 87, 1, 2, 1], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", 77, 85, 1, 2, 1], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", 21, 84, 4, 4, 4], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", 62, 75, 1, 2, 1], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", 6, 63, 10, 11, 10], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", 6, 60, 10, 10, 10], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", 6, 48, 8, 8, 8], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", 12, 36, 3, 4, 2], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", 6, 36, 6, 6, 6], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", 6, 21, 4, 4, 3], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", 6, 13, 2, 3, 2]]}}
{"total": {"columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", 90214.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 85427.0], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", 62347.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", 47476.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", 41486.0], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 36210.0], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 32761.0], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", 26289.0], ["volta_sgemm_128x64_nt", 23803.0], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", 22477.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 18728.0], ["volta_sgemm_128x64_nn", 14530.0], ["volta_scudnn_128x64_stridedB_interior_nn_v1", 11515.0], ["volta_scudnn_128x64_relu_interior_nn_v1", 10280.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 8372.0], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", 7728.0], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", 7213.0], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 7133.0], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", 7045.0], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", 5920.0], ["volta_scudnn_128x128_stridedB_interior_nn_v1", 5763.0], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 5352.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 5335.0], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 4882.0], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", 4795.0], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", 4662.0], ["volta_scudnn_128x128_stridedB_medium_nn_v1", 4373.0], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 4023.0], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", 4007.0], ["volta_scudnn_128x64_relu_medium_nn_v1", 3850.0], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", 3731.0], ["volta_scudnn_128x128_stridedB_small_nn_v1", 3726.0], ["volta_scudnn_128x64_relu_small_nn_v1", 3427.0], ["volta_scudnn_128x128_relu_interior_nn_v1", 3340.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", 2771.0], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", 2699.0], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 2540.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", 2534.0], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", 2479.0], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", 2313.0], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", 1341.0], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", 1320.0], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 864.0], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", 601.0], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", 352.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", 327.0], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", 258.0], ["volta_sgemm_64x32_sliced1x4_nn", 161.0], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", 161.0], ["volta_sgemm_64x32_sliced1x4_tn", 144.0], ["volta_sgemm_128x32_nt", 115.0], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", 87.0], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", 85.0], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", 84.0], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", 75.0], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", 63.0], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", 60.0], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", 48.0], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", 36.0], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", 36.0], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", 21.0], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", 13.0]]}}
