name: libkineto PR Test on A10G

on:
  push:
    branches:
      - main
  pull_request:

# Use TorchBench's docker image which has all basic dependencies.
env:
  DOCKER_IMAGE: "ghcr.io/pytorch/torchbench:latest"

jobs:
  pr-test:
    # AWS A10G GPU instance label: linux.g5.4xlarge.nvidia.gpu
    # OS version: Amazon Linux 2
    runs-on: linux.g5.4xlarge.nvidia.gpu
    timeout-minutes: 180 # 3 hours
    steps:
      - name: Checkout Kineto
        uses: actions/checkout@v5
        with:
          path: kineto
          submodules: recursive

      - name: Pull docker image
        uses: pytorch/test-infra/.github/actions/pull-docker-image@main
        with:
          docker-image: ${{ env.DOCKER_IMAGE }}

      - name: Install NVIDIA Driver, docker runtime, set GPU_FLAG
        uses: pytorch/test-infra/.github/actions/setup-nvidia@main

      - name: Get env vars
        run: |
          echo GITHUB_WORKFLOW   = $GITHUB_WORKFLOW
          echo HOME              = $HOME
          echo GITHUB_ACTION     = $GITHUB_ACTION
          echo GITHUB_ACTIONS    = $GITHUB_ACTIONS
          echo GITHUB_REPOSITORY = $GITHUB_REPOSITORY
          echo GITHUB_EVENT_NAME = $GITHUB_EVENT_NAME
          echo GITHUB_EVENT_PATH = $GITHUB_EVENT_PATH
          echo GITHUB_WORKSPACE  = $GITHUB_WORKSPACE
          echo GITHUB_SHA        = $GITHUB_SHA
          echo GITHUB_REF        = $GITHUB_REF

      - name: Build libkineto (static and shared library) and tests
        run: |
          container_name=$(docker run \
            ${GPU_FLAG:-} \
            --tty \
            --detach \
            --shm-size=32gb \
            -v "${PWD}/kineto:/kineto" \
            -w / \
            "${{ env.DOCKER_IMAGE }}"
          )
          echo "Container name: ${container_name}"

          docker exec -t -w "/kineto" "${container_name}" bash -c "
            set -eux
            mkdir build_static
            mkdir build_shared
            pip install cmake
          "

          docker exec -t -w "/kineto/build_static" "${container_name}" bash -c "
            set -eux
            cmake -DKINETO_LIBRARY_TYPE=static ../libkineto/
            make -j
          "

          docker exec -t -w "/kineto/build_shared" "${container_name}" bash -c "
            set -eux
            cmake -DKINETO_LIBRARY_TYPE=shared ../libkineto/
            make -j
          "

          docker exec -t -w "/kineto/build_static" "${container_name}" bash -c "make test"

      - name: Clone PyTorch
        run: |
          container_name=$(docker ps -lq)
          docker exec -t -w "/" "${container_name}" bash -c "
            set -eux
            git clone --recursive https://github.com/pytorch/pytorch.git
          "

      - name: Replace PyTorch's Kineto with PR version
        run: |
          container_name=$(docker ps -lq)
          docker exec -t -w "/pytorch" "${container_name}" bash -c "
            set -eux
            rm -rf third_party/kineto
            ln -s /kineto third_party/kineto
          "

      - name: Build PyTorch from source
        run: |
          container_name=$(docker ps -lq)
          docker exec -t -w "/pytorch" "${container_name}" bash -c "
            set -eux
            pip install -r requirements.txt
            export USE_CUDA=1
            export BUILD_TEST=1
            python setup.py develop
          "

      - name: Generate dynamic test exclusions
        id: exclusions
        run: |
          # Generate pytest exclusion arguments based on PyTorch trunk test status
          # This queries PyTorch's test-infra and recent runs to identify currently
          # failing profiler tests, preventing Kineto PRs from being blocked by
          # pre-existing PyTorch issues.
          python3 kineto/.github/scripts/get_trunk_test_exclusions.py > exclusions.txt
          echo "Generated exclusions:"
          cat exclusions.txt

      - name: Run PyTorch profiler tests
        run: |
          container_name=$(docker ps -lq)
          # Copy exclusions file into container
          docker cp exclusions.txt "${container_name}:/exclusions.txt"

          docker exec -t -w "/pytorch" "${container_name}" bash -c "
            set -eux
            # Read dynamically generated test exclusions based on PyTorch trunk status
            # This prevents Kineto PRs from being blocked by pre-existing PyTorch issues
            # while maintaining test coverage for new issues introduced by Kineto changes.
            EXCLUSIONS=\$(cat /exclusions.txt)
            python -m pytest test/profiler/ -v \$EXCLUSIONS
          "

      - name: Teardown Linux
        uses: pytorch/test-infra/.github/actions/teardown-linux@main
        if: always()

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.sha }}-${{ github.event_name == 'workflow_dispatch' }}
  cancel-in-progress: true
