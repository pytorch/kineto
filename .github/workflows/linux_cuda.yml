name: Linux CUDA build and test

on:
  push:
    branches:
      - main
  pull_request:

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.sha }}-${{ github.event_name == 'workflow_dispatch' }}
  cancel-in-progress: true

jobs:
  pr-test:
    uses: pytorch/test-infra/.github/workflows/linux_job_v2.yml@main
    with:
      job-name: linux-cuda-build-and-test
      # AWS A10G GPU instance
      runner: linux.g5.4xlarge.nvidia.gpu
      timeout: 180
      submodules: recursive
      gpu-arch-type: cuda
      gpu-arch-version: "12.6"
      script: |
        set -eux

        # Build libkineto (static and shared library)
        pip install cmake
        mkdir -p build_static build_shared

        pushd build_static
        cmake -DKINETO_LIBRARY_TYPE=static ../libkineto/
        make -j
        popd

        pushd build_shared
        cmake -DKINETO_LIBRARY_TYPE=shared ../libkineto/
        make -j
        popd

        # Run libkineto tests
        pushd build_static
        make test
        popd

        # Clone PyTorch and replace its Kineto with PR version
        PYTORCH_DIR="${RUNNER_TEMP}/pytorch"
        git clone --recursive --branch viable/strict https://github.com/pytorch/pytorch.git "${PYTORCH_DIR}"

        pushd "${PYTORCH_DIR}"
        rm -rf third_party/kineto
        ln -s "${GITHUB_WORKSPACE}/${GITHUB_REPOSITORY}" third_party/kineto

        # Build PyTorch from source
        pip install -r requirements.txt
        export USE_CUDA=1
        export BUILD_TEST=1
        python setup.py develop

        # Run PyTorch profiler tests
        # TODO: Dynamically add/remove tests to the exclusion list based on their
        # status on trunk instead of maintaining a hardcoded list of known failures.
        # This will prevent the list from becoming stale as tests get fixed upstream.
        python -m pytest test/profiler/ -v \
          --deselect=test/profiler/test_memory_profiler.py::TestDataFlow::test_data_flow_graph_complicated \
          --deselect=test/profiler/test_memory_profiler.py::TestMemoryProfilerE2E::test_categories_e2e_sequential_fwd_bwd \
          --deselect=test/profiler/test_memory_profiler.py::TestMemoryProfilerE2E::test_categories_e2e_simple_fwd_bwd \
          --deselect=test/profiler/test_memory_profiler.py::TestMemoryProfilerE2E::test_categories_e2e_simple_fwd_bwd_step \
          --deselect=test/profiler/test_profiler.py::TestProfiler::test_kineto \
          --deselect=test/profiler/test_profiler.py::TestProfiler::test_user_annotation \
          --deselect=test/profiler/test_profiler.py::TestExperimentalUtils::test_fuzz_symbolize \
          --deselect=test/profiler/test_profiler.py::TestExperimentalUtils::test_profiler_debug_autotuner \
          --deselect=test/profiler/test_torch_tidy.py::TestTorchTidyProfiler::test_tensorimpl_invalidation_scalar_args
        popd
