{"steps": {"columns": [{"type": "string", "name": "Step"}, {"type": "number", "name": "Kernel"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memcpy"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Communication"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memset"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Runtime"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "DataLoader"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "CPU Exec"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Other"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}], "rows": [["5", 100863, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 129983us<br><b>Kernel: 100863us</b><br>Percentage: 77.6%</div>", 1948, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 129983us<br><b>Memcpy: 1948us</b><br>Percentage: 1.5%</div>", 69, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 129983us<br><b>Memset: 69us</b><br>Percentage: 0.05%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 129983us<br><b>Communication: 0us</b><br>Percentage: 0.0%</div>", 3346, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 129983us<br><b>Runtime: 3346us</b><br>Percentage: 2.57%</div>", 10023, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 129983us<br><b>DataLoader: 10023us</b><br>Percentage: 7.71%</div>", 12460, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 129983us<br><b>CPU Exec: 12460us</b><br>Percentage: 9.59%</div>", 1274, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 129983us<br><b>Other: 1274us</b><br>Percentage: 0.98%</div>"], ["6", 100576, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 158499us<br><b>Kernel: 100576us</b><br>Percentage: 63.46%</div>", 2436, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 158499us<br><b>Memcpy: 2436us</b><br>Percentage: 1.54%</div>", 69, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 158499us<br><b>Memset: 69us</b><br>Percentage: 0.04%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 158499us<br><b>Communication: 0us</b><br>Percentage: 0.0%</div>", 3144, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 158499us<br><b>Runtime: 3144us</b><br>Percentage: 1.98%</div>", 37553, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 158499us<br><b>DataLoader: 37553us</b><br>Percentage: 23.69%</div>", 13420, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 158499us<br><b>CPU Exec: 13420us</b><br>Percentage: 8.47%</div>", 1301, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 158499us<br><b>Other: 1301us</b><br>Percentage: 0.82%</div>"], ["7", 100821, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 140334us<br><b>Kernel: 100821us</b><br>Percentage: 71.84%</div>", 2111, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 140334us<br><b>Memcpy: 2111us</b><br>Percentage: 1.5%</div>", 69, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 140334us<br><b>Memset: 69us</b><br>Percentage: 0.05%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 140334us<br><b>Communication: 0us</b><br>Percentage: 0.0%</div>", 1756, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 140334us<br><b>Runtime: 1756us</b><br>Percentage: 1.25%</div>", 28965, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 140334us<br><b>DataLoader: 28965us</b><br>Percentage: 20.64%</div>", 5907, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 140334us<br><b>CPU Exec: 5907us</b><br>Percentage: 4.21%</div>", 705, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 140334us<br><b>Other: 705us</b><br>Percentage: 0.5%</div>"], ["8", 101109, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 163126us<br><b>Kernel: 101109us</b><br>Percentage: 61.98%</div>", 2078, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 163126us<br><b>Memcpy: 2078us</b><br>Percentage: 1.27%</div>", 69, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 163126us<br><b>Memset: 69us</b><br>Percentage: 0.04%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 163126us<br><b>Communication: 0us</b><br>Percentage: 0.0%</div>", 2040, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 163126us<br><b>Runtime: 2040us</b><br>Percentage: 1.25%</div>", 49998, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 163126us<br><b>DataLoader: 49998us</b><br>Percentage: 30.65%</div>", 7087, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 163126us<br><b>CPU Exec: 7087us</b><br>Percentage: 4.34%</div>", 745, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 163126us<br><b>Other: 745us</b><br>Percentage: 0.46%</div>"], ["9", 101108, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 141407us<br><b>Kernel: 101108us</b><br>Percentage: 71.5%</div>", 2072, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 141407us<br><b>Memcpy: 2072us</b><br>Percentage: 1.47%</div>", 69, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 141407us<br><b>Memset: 69us</b><br>Percentage: 0.05%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 141407us<br><b>Communication: 0us</b><br>Percentage: 0.0%</div>", 2926, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 141407us<br><b>Runtime: 2926us</b><br>Percentage: 2.07%</div>", 25338, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 141407us<br><b>DataLoader: 25338us</b><br>Percentage: 17.92%</div>", 9084, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 141407us<br><b>CPU Exec: 9084us</b><br>Percentage: 6.42%</div>", 810, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 141407us<br><b>Other: 810us</b><br>Percentage: 0.57%</div>"], ["10", 100732, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 159068us<br><b>Kernel: 100732us</b><br>Percentage: 63.33%</div>", 2089, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 159068us<br><b>Memcpy: 2089us</b><br>Percentage: 1.31%</div>", 69, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 159068us<br><b>Memset: 69us</b><br>Percentage: 0.04%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 159068us<br><b>Communication: 0us</b><br>Percentage: 0.0%</div>", 4174, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 159068us<br><b>Runtime: 4174us</b><br>Percentage: 2.62%</div>", 35514, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 159068us<br><b>DataLoader: 35514us</b><br>Percentage: 22.33%</div>", 14748, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 159068us<br><b>CPU Exec: 14748us</b><br>Percentage: 9.27%</div>", 1742, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 159068us<br><b>Other: 1742us</b><br>Percentage: 1.1%</div>"]]}, "performance": [{"name": "Average Step Time", "description": "", "value": 148736, "extra": 100, "children": [{"name": "Kernel", "description": "", "value": 100868, "extra": 67.82}, {"name": "Memcpy", "description": "", "value": 2122, "extra": 1.43}, {"name": "Memset", "description": "", "value": 69, "extra": 0.05}, {"name": "Communication", "description": "", "value": 0, "extra": 0.0}, {"name": "Runtime", "description": "", "value": 2898, "extra": 1.95}, {"name": "DataLoader", "description": "", "value": 31232, "extra": 21.0}, {"name": "CPU Exec", "description": "", "value": 10451, "extra": 7.03}, {"name": "Other", "description": "", "value": 1096, "extra": 0.74}]}], "recommendations": "<ul><li>This run has high time cost on input data loading. 21.0% of the step time is in DataLoader. You could try to set num_workers on DataLoader's construction and enable multi-processes on data loading. Reference: <a href =\"https://pytorch.org/docs/stable/data.html#single-and-multi-process-data-loading\" target=\"_blank\">Single- and Multi-process Data Loading</a></li></ul>", "environments": [{"title": "Number of Worker(s)", "value": "1"}, {"title": "Device Type", "value": "GPU"}, {"title": "GPU Utilization of GPU0", "value": "67.82 %"}]}
{"device_total_time": {"title": "Device Total Time (us)", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward", 285514], ["CudnnConvolutionBackward", 285514], ["aten::cudnn_convolution_backward_weight", 149670], ["aten::cudnn_convolution_backward_input", 135844], ["aten::cudnn_convolution", 135735], ["aten::_convolution", 135735], ["aten::convolution", 135735], ["aten::conv2d", 135735], ["aten::cudnn_batch_norm_backward", 56884], ["CudnnBatchNormBackward", 56884], ["aten::cudnn_batch_norm", 33292], ["aten::_batch_norm_impl_index", 33292], ["aten::batch_norm", 33292], ["aten::threshold_backward", 26258], ["ReluBackward1", 26258], ["aten::add_", 23357], ["aten::threshold_", 17759], ["aten::relu_", 17759], ["aten::copy_", 12734], ["aten::to", 12734], ["aten::max_pool2d_with_indices_backward", 5046], ["MaxPool2DWithIndicesBackward", 5046], ["torch::autograd::AccumulateGrad", 2915], ["aten::fill_", 2414], ["aten::zero_", 2408], ["aten::mul_", 2380], ["aten::max_pool2d_with_indices", 1341], ["aten::max_pool2d", 1341], ["aten::zeros_like", 948], ["aten::add", 325], ["aten::mm", 295], ["AddmmBackward", 295], ["aten::mean", 256], ["aten::adaptive_avg_pool2d", 256], ["aten::addmm", 201], ["aten::div", 162], ["MeanBackward1", 162], ["aten::_log_softmax_backward_data", 64], ["LogSoftmaxBackward", 64], ["aten::_log_softmax", 60], ["aten::log_softmax", 60], ["aten::nll_loss_forward", 20], ["aten::nll_loss", 20], ["aten::nll_loss_backward", 18], ["NllLossBackward", 18], ["aten::ones_like", 6]]}, "device_self_time": {"title": "Device Self Time (us)", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward_weight", 149670], ["aten::cudnn_convolution_backward_input", 135844], ["aten::cudnn_convolution", 135735], ["aten::cudnn_batch_norm_backward", 56884], ["aten::cudnn_batch_norm", 33292], ["aten::threshold_backward", 26258], ["aten::add_", 23357], ["aten::threshold_", 17759], ["aten::copy_", 12734], ["aten::max_pool2d_with_indices_backward", 4098], ["aten::fill_", 2414], ["aten::mul_", 2380], ["aten::max_pool2d_with_indices", 1341], ["aten::add", 325], ["aten::mm", 295], ["aten::mean", 256], ["aten::addmm", 201], ["aten::div", 162], ["aten::_log_softmax_backward_data", 64], ["aten::_log_softmax", 60], ["aten::nll_loss_forward", 20], ["aten::nll_loss_backward", 18]]}, "host_total_time": {"title": "Host Total Time (us)", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::add_", 96814], ["CudnnConvolutionBackward", 90857], ["aten::cudnn_convolution_backward", 87104], ["aten::conv2d", 61610], ["aten::copy_", 60140], ["aten::convolution", 57644], ["aten::batch_norm", 55154], ["aten::_convolution", 53789], ["aten::_batch_norm_impl_index", 51122], ["aten::cudnn_convolution", 49275], ["aten::cudnn_batch_norm", 47638], ["aten::to", 46057], ["aten::cudnn_convolution_backward_weight", 39006], ["aten::cudnn_convolution_backward_input", 38583], ["aten::mul_", 36843], ["aten::zero_", 36160], ["torch::autograd::AccumulateGrad", 34208], ["aten::empty", 33098], ["aten::stack", 33058], ["CudnnBatchNormBackward", 32186], ["aten::cat", 31169], ["aten::_cat", 30970], ["aten::div", 30671], ["aten::cudnn_batch_norm_backward", 27883], ["aten::contiguous", 24479], ["aten::fill_", 21081], ["aten::relu_", 16620], ["ReluBackward1", 15142], ["aten::add", 14945], ["aten::threshold_backward", 12601], ["aten::threshold_", 9128], ["aten::empty_like", 8255], ["aten::view", 4811], ["aten::resize_", 3415], ["aten::permute", 3161], ["aten::set_", 2994], ["aten::empty_strided", 1725], ["AddmmBackward", 1462], ["aten::unsqueeze", 1293], ["aten::addmm", 1274], ["aten::as_strided", 948], ["aten::mm", 847], ["MaxPool2DWithIndicesBackward", 763], ["aten::max_pool2d", 732], ["NllLossBackward", 719], ["aten::max_pool2d_with_indices_backward", 686], ["aten::t", 664], ["aten::zeros", 651], ["aten::max_pool2d_with_indices", 644], ["MeanBackward1", 606], ["aten::nll_loss_backward", 590], ["aten::adaptive_avg_pool2d", 566], ["aten::log_softmax", 527], ["aten::nll_loss", 500], ["aten::mean", 484], ["LogSoftmaxBackward", 451], ["aten::_log_softmax", 447], ["aten::nll_loss_forward", 425], ["aten::ones_like", 410], ["aten::_log_softmax_backward_data", 357], ["aten::zeros_like", 339], ["aten::transpose", 309], ["AddBackward0", 309], ["aten::reshape", 228], ["aten::flatten", 206], ["aten::expand", 141], ["TBackward", 140], ["ViewBackward", 121], ["aten::narrow", 87], ["aten::detach_", 64], ["aten::resize_as_", 54], ["aten::slice", 52], ["aten::conj", 46], ["detach_", 33]]}, "host_self_time": {"title": "Host Self Time (us)", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::add_", 64646], ["aten::copy_", 45838], ["aten::cudnn_convolution", 34235], ["aten::empty", 33098], ["aten::_cat", 30756], ["aten::cudnn_batch_norm", 26997], ["aten::div", 25915], ["aten::cudnn_convolution_backward_input", 25552], ["aten::mul_", 24290], ["aten::cudnn_convolution_backward_weight", 22973], ["aten::cudnn_batch_norm_backward", 15840], ["aten::zero_", 15259], ["aten::add", 9687], ["aten::cudnn_convolution_backward", 9515], ["aten::fill_", 9102], ["aten::relu_", 7492], ["aten::threshold_backward", 7183], ["torch::autograd::AccumulateGrad", 6798], ["aten::view", 4811], ["aten::to", 4680], ["aten::_convolution", 4514], ["aten::empty_like", 4430], ["CudnnBatchNormBackward", 4303], ["aten::threshold_", 4261], ["aten::batch_norm", 4032], ["aten::conv2d", 3966], ["aten::convolution", 3855], ["CudnnConvolutionBackward", 3753], ["aten::_batch_norm_impl_index", 3484], ["aten::resize_", 3415], ["aten::set_", 2994], ["aten::permute", 2703], ["ReluBackward1", 2541], ["aten::contiguous", 2069], ["aten::empty_strided", 1725], ["aten::as_strided", 948], ["aten::unsqueeze", 925], ["aten::addmm", 699], ["aten::stack", 596], ["aten::zeros", 463], ["aten::mm", 439], ["aten::max_pool2d_with_indices", 367], ["aten::t", 355], ["aten::nll_loss_forward", 310], ["AddBackward0", 309], ["aten::mean", 280], ["aten::nll_loss_backward", 278], ["aten::transpose", 226], ["aten::_log_softmax", 225], ["aten::max_pool2d_with_indices_backward", 211], ["aten::cat", 199], ["AddmmBackward", 195], ["aten::_log_softmax_backward_data", 153], ["NllLossBackward", 129], ["aten::expand", 113], ["MeanBackward1", 103], ["aten::ones_like", 100], ["LogSoftmaxBackward", 94], ["aten::max_pool2d", 88], ["aten::adaptive_avg_pool2d", 82], ["aten::log_softmax", 80], ["MaxPool2DWithIndicesBackward", 77], ["aten::nll_loss", 75], ["aten::reshape", 71], ["aten::flatten", 65], ["aten::zeros_like", 53], ["aten::conj", 46], ["aten::resize_as_", 44], ["aten::slice", 41], ["aten::narrow", 35], ["ViewBackward", 34], ["detach_", 33], ["aten::detach_", 31], ["TBackward", 29]]}}
[{"name": "aten::cudnn_convolution_backward_weight", "calls": 318, "device_self_duration": 149670, "device_total_duration": 149670, "host_self_duration": 22973, "host_total_duration": 39006, "has_call_stack": false}, {"name": "aten::cudnn_convolution_backward_input", "calls": 312, "device_self_duration": 135844, "device_total_duration": 135844, "host_self_duration": 25552, "host_total_duration": 38583, "has_call_stack": false}, {"name": "aten::cudnn_convolution", "calls": 318, "device_self_duration": 135735, "device_total_duration": 135735, "host_self_duration": 34235, "host_total_duration": 49275, "has_call_stack": false}, {"name": "aten::cudnn_batch_norm_backward", "calls": 318, "device_self_duration": 56884, "device_total_duration": 56884, "host_self_duration": 15840, "host_total_duration": 27883, "has_call_stack": false}, {"name": "aten::cudnn_batch_norm", "calls": 318, "device_self_duration": 33292, "device_total_duration": 33292, "host_self_duration": 26997, "host_total_duration": 47638, "has_call_stack": false}, {"name": "aten::threshold_backward", "calls": 294, "device_self_duration": 26258, "device_total_duration": 26258, "host_self_duration": 7183, "host_total_duration": 12601, "has_call_stack": false}, {"name": "aten::add_", "calls": 2994, "device_self_duration": 23357, "device_total_duration": 23357, "host_self_duration": 64646, "host_total_duration": 96814, "has_call_stack": false}, {"name": "aten::threshold_", "calls": 294, "device_self_duration": 17759, "device_total_duration": 17759, "host_self_duration": 4261, "host_total_duration": 9128, "has_call_stack": false}, {"name": "aten::copy_", "calls": 588, "device_self_duration": 12734, "device_total_duration": 12734, "host_self_duration": 45838, "host_total_duration": 60140, "has_call_stack": false}, {"name": "aten::max_pool2d_with_indices_backward", "calls": 6, "device_self_duration": 4098, "device_total_duration": 5046, "host_self_duration": 211, "host_total_duration": 686, "has_call_stack": false}, {"name": "aten::fill_", "calls": 978, "device_self_duration": 2414, "device_total_duration": 2414, "host_self_duration": 9102, "host_total_duration": 21081, "has_call_stack": false}, {"name": "aten::mul_", "calls": 966, "device_self_duration": 2380, "device_total_duration": 2380, "host_self_duration": 24290, "host_total_duration": 36843, "has_call_stack": false}, {"name": "aten::max_pool2d_with_indices", "calls": 6, "device_self_duration": 1341, "device_total_duration": 1341, "host_self_duration": 367, "host_total_duration": 644, "has_call_stack": false}, {"name": "aten::add", "calls": 318, "device_self_duration": 325, "device_total_duration": 325, "host_self_duration": 9687, "host_total_duration": 14945, "has_call_stack": false}, {"name": "aten::mm", "calls": 12, "device_self_duration": 295, "device_total_duration": 295, "host_self_duration": 439, "host_total_duration": 847, "has_call_stack": false}, {"name": "aten::mean", "calls": 6, "device_self_duration": 256, "device_total_duration": 256, "host_self_duration": 280, "host_total_duration": 484, "has_call_stack": false}, {"name": "aten::addmm", "calls": 6, "device_self_duration": 201, "device_total_duration": 201, "host_self_duration": 699, "host_total_duration": 1274, "has_call_stack": false}, {"name": "aten::div", "calls": 198, "device_self_duration": 162, "device_total_duration": 162, "host_self_duration": 25915, "host_total_duration": 30671, "has_call_stack": false}, {"name": "aten::_log_softmax_backward_data", "calls": 6, "device_self_duration": 64, "device_total_duration": 64, "host_self_duration": 153, "host_total_duration": 357, "has_call_stack": false}, {"name": "aten::_log_softmax", "calls": 6, "device_self_duration": 60, "device_total_duration": 60, "host_self_duration": 225, "host_total_duration": 447, "has_call_stack": false}, {"name": "aten::nll_loss_forward", "calls": 6, "device_self_duration": 20, "device_total_duration": 20, "host_self_duration": 310, "host_total_duration": 425, "has_call_stack": false}, {"name": "aten::nll_loss_backward", "calls": 6, "device_self_duration": 18, "device_total_duration": 18, "host_self_duration": 278, "host_total_duration": 590, "has_call_stack": false}, {"name": "aten::empty", "calls": 5748, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 33098, "host_total_duration": 33098, "has_call_stack": false}, {"name": "aten::zero_", "calls": 996, "device_self_duration": 0, "device_total_duration": 2408, "host_self_duration": 15259, "host_total_duration": 36160, "has_call_stack": false}, {"name": "aten::zeros", "calls": 24, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 463, "host_total_duration": 651, "has_call_stack": false}, {"name": "aten::set_", "calls": 192, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 2994, "host_total_duration": 2994, "has_call_stack": false}, {"name": "aten::view", "calls": 840, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 4811, "host_total_duration": 4811, "has_call_stack": false}, {"name": "aten::as_strided", "calls": 432, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 948, "host_total_duration": 948, "has_call_stack": false}, {"name": "aten::permute", "calls": 192, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 2703, "host_total_duration": 3161, "has_call_stack": false}, {"name": "aten::empty_like", "calls": 534, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 4430, "host_total_duration": 8255, "has_call_stack": false}, {"name": "aten::contiguous", "calls": 192, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 2069, "host_total_duration": 24479, "has_call_stack": false}, {"name": "aten::empty_strided", "calls": 402, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 1725, "host_total_duration": 1725, "has_call_stack": false}, {"name": "aten::to", "calls": 408, "device_self_duration": 0, "device_total_duration": 12734, "host_self_duration": 4680, "host_total_duration": 46057, "has_call_stack": false}, {"name": "aten::unsqueeze", "calls": 192, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 925, "host_total_duration": 1293, "has_call_stack": false}, {"name": "aten::resize_", "calls": 1926, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 3415, "host_total_duration": 3415, "has_call_stack": false}, {"name": "aten::slice", "calls": 6, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 41, "host_total_duration": 52, "has_call_stack": false}, {"name": "aten::narrow", "calls": 6, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 35, "host_total_duration": 87, "has_call_stack": false}, {"name": "aten::_cat", "calls": 6, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 30756, "host_total_duration": 30970, "has_call_stack": false}, {"name": "aten::cat", "calls": 6, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 199, "host_total_duration": 31169, "has_call_stack": false}, {"name": "aten::stack", "calls": 6, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 596, "host_total_duration": 33058, "has_call_stack": false}, {"name": "detach_", "calls": 6, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 33, "host_total_duration": 33, "has_call_stack": false}, {"name": "aten::detach_", "calls": 6, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 31, "host_total_duration": 64, "has_call_stack": false}, {"name": "aten::_convolution", "calls": 318, "device_self_duration": 0, "device_total_duration": 135735, "host_self_duration": 4514, "host_total_duration": 53789, "has_call_stack": false}, {"name": "aten::convolution", "calls": 318, "device_self_duration": 0, "device_total_duration": 135735, "host_self_duration": 3855, "host_total_duration": 57644, "has_call_stack": false}, {"name": "aten::conv2d", "calls": 318, "device_self_duration": 0, "device_total_duration": 135735, "host_self_duration": 3966, "host_total_duration": 61610, "has_call_stack": false}, {"name": "aten::_batch_norm_impl_index", "calls": 318, "device_self_duration": 0, "device_total_duration": 33292, "host_self_duration": 3484, "host_total_duration": 51122, "has_call_stack": false}, {"name": "aten::batch_norm", "calls": 318, "device_self_duration": 0, "device_total_duration": 33292, "host_self_duration": 4032, "host_total_duration": 55154, "has_call_stack": false}, {"name": "aten::relu_", "calls": 294, "device_self_duration": 0, "device_total_duration": 17759, "host_self_duration": 7492, "host_total_duration": 16620, "has_call_stack": false}, {"name": "aten::max_pool2d", "calls": 6, "device_self_duration": 0, "device_total_duration": 1341, "host_self_duration": 88, "host_total_duration": 732, "has_call_stack": false}, {"name": "aten::adaptive_avg_pool2d", "calls": 6, "device_self_duration": 0, "device_total_duration": 256, "host_self_duration": 82, "host_total_duration": 566, "has_call_stack": false}, {"name": "aten::reshape", "calls": 12, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 71, "host_total_duration": 228, "has_call_stack": false}, {"name": "aten::flatten", "calls": 6, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 65, "host_total_duration": 206, "has_call_stack": false}, {"name": "aten::transpose", "calls": 30, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 226, "host_total_duration": 309, "has_call_stack": false}, {"name": "aten::t", "calls": 30, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 355, "host_total_duration": 664, "has_call_stack": false}, {"name": "aten::expand", "calls": 12, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 113, "host_total_duration": 141, "has_call_stack": false}, {"name": "aten::log_softmax", "calls": 6, "device_self_duration": 0, "device_total_duration": 60, "host_self_duration": 80, "host_total_duration": 527, "has_call_stack": false}, {"name": "aten::nll_loss", "calls": 6, "device_self_duration": 0, "device_total_duration": 20, "host_self_duration": 75, "host_total_duration": 500, "has_call_stack": false}, {"name": "aten::ones_like", "calls": 6, "device_self_duration": 0, "device_total_duration": 6, "host_self_duration": 100, "host_total_duration": 410, "has_call_stack": false}, {"name": "NllLossBackward", "calls": 6, "device_self_duration": 0, "device_total_duration": 18, "host_self_duration": 129, "host_total_duration": 719, "has_call_stack": false}, {"name": "LogSoftmaxBackward", "calls": 6, "device_self_duration": 0, "device_total_duration": 64, "host_self_duration": 94, "host_total_duration": 451, "has_call_stack": false}, {"name": "aten::conj", "calls": 12, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 46, "host_total_duration": 46, "has_call_stack": false}, {"name": "AddmmBackward", "calls": 6, "device_self_duration": 0, "device_total_duration": 295, "host_self_duration": 195, "host_total_duration": 1462, "has_call_stack": false}, {"name": "torch::autograd::AccumulateGrad", "calls": 966, "device_self_duration": 0, "device_total_duration": 2915, "host_self_duration": 6798, "host_total_duration": 34208, "has_call_stack": false}, {"name": "TBackward", "calls": 6, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 29, "host_total_duration": 140, "has_call_stack": false}, {"name": "ViewBackward", "calls": 6, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 34, "host_total_duration": 121, "has_call_stack": false}, {"name": "MeanBackward1", "calls": 6, "device_self_duration": 0, "device_total_duration": 162, "host_self_duration": 103, "host_total_duration": 606, "has_call_stack": false}, {"name": "ReluBackward1", "calls": 294, "device_self_duration": 0, "device_total_duration": 26258, "host_self_duration": 2541, "host_total_duration": 15142, "has_call_stack": false}, {"name": "AddBackward0", "calls": 96, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 309, "host_total_duration": 309, "has_call_stack": false}, {"name": "CudnnBatchNormBackward", "calls": 318, "device_self_duration": 0, "device_total_duration": 56884, "host_self_duration": 4303, "host_total_duration": 32186, "has_call_stack": false}, {"name": "aten::cudnn_convolution_backward", "calls": 318, "device_self_duration": 0, "device_total_duration": 285514, "host_self_duration": 9515, "host_total_duration": 87104, "has_call_stack": false}, {"name": "CudnnConvolutionBackward", "calls": 318, "device_self_duration": 0, "device_total_duration": 285514, "host_self_duration": 3753, "host_total_duration": 90857, "has_call_stack": false}, {"name": "aten::zeros_like", "calls": 6, "device_self_duration": 0, "device_total_duration": 948, "host_self_duration": 53, "host_total_duration": 339, "has_call_stack": false}, {"name": "aten::resize_as_", "calls": 6, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 44, "host_total_duration": 54, "has_call_stack": false}, {"name": "MaxPool2DWithIndicesBackward", "calls": 6, "device_self_duration": 0, "device_total_duration": 5046, "host_self_duration": 77, "host_total_duration": 763, "has_call_stack": false}]
{"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Total Duration (us)"}, {"type": "number", "name": "Mean Duration (us)"}, {"type": "number", "name": "Max Duration (us)"}, {"type": "number", "name": "Min Duration (us)"}], "rows": [["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", 167, 86835, 520, 1084, 330], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", 287, 61395, 214, 799, 43], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 104, 53577, 515, 815, 393], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", 609, 47050, 77, 364, 6], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", 3489, 41190, 12, 364, 1], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 90, 40341, 448, 753, 381], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 60, 28063, 468, 851, 361], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", 72, 27624, 384, 667, 354], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", 34, 27184, 800, 885, 664], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", 150, 26234, 175, 426, 50], ["volta_sgemm_128x64_nt", 126, 23737, 188, 206, 155], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", 48, 21753, 453, 705, 328], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", 39, 14259, 366, 370, 361], ["volta_sgemm_128x64_nn", 60, 11407, 190, 207, 156], ["volta_scudnn_128x64_stridedB_interior_nn_v1", 34, 10904, 321, 525, 263], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 12, 8816, 735, 784, 660], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 14, 8346, 596, 990, 207], ["volta_scudnn_128x64_relu_interior_nn_v1", 24, 7210, 300, 311, 295], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", 168, 7058, 42, 87, 14], ["volta_scudnn_128x128_stridedB_interior_nn_v1", 21, 5717, 272, 275, 269], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", 167, 5482, 33, 158, 6], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 12, 5341, 445, 449, 442], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 7, 5298, 757, 780, 732], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", 123, 5250, 43, 68, 19], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 6, 4895, 816, 822, 809], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", 7, 4781, 683, 684, 682], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 123, 4765, 39, 63, 17], ["volta_scudnn_128x128_stridedB_medium_nn_v1", 14, 4312, 308, 325, 299], ["volta_scudnn_128x64_relu_medium_nn_v1", 6, 3829, 638, 641, 637], ["volta_scudnn_128x128_stridedB_small_nn_v1", 7, 3709, 530, 533, 527], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 6, 3533, 589, 659, 573], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", 6, 3532, 589, 672, 569], ["volta_scudnn_128x64_relu_small_nn_v1", 12, 3395, 283, 296, 270], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", 1127, 2779, 2, 24, 1], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", 123, 2617, 21, 66, 4], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 63, 2602, 41, 60, 21], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", 979, 2572, 3, 158, 0], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", 63, 2449, 39, 61, 16], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", 54, 2283, 42, 74, 19], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", 12, 1699, 142, 184, 98], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", 6, 1341, 224, 224, 223], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", 63, 1306, 21, 63, 4], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 6, 848, 141, 142, 140], ["volta_scudnn_128x64_stridedB_small_nn_v1", 7, 666, 95, 96, 94], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", 131, 330, 3, 4, 2], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", 318, 325, 1, 2, 1], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", 6, 256, 43, 43, 42], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", 154, 198, 1, 2, 1], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", 154, 174, 1, 2, 1], ["volta_sgemm_64x32_sliced1x4_nn", 6, 166, 28, 28, 27], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", 6, 162, 27, 27, 27], ["volta_sgemm_64x32_sliced1x4_tn", 6, 145, 24, 25, 24], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", 39, 135, 3, 5, 3], ["volta_sgemm_128x32_nt", 6, 117, 20, 20, 19], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", 83, 90, 1, 2, 1], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", 6, 64, 11, 11, 10], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", 6, 60, 10, 10, 10], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", 6, 48, 8, 8, 8], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", 12, 35, 3, 4, 2], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", 6, 33, 6, 6, 5], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", 6, 20, 3, 4, 3], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", 6, 12, 2, 2, 2]]}}
{"total": {"columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", 86835.0], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", 61395.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 53577.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", 47050.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", 41190.0], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 40341.0], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 28063.0], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", 27624.0], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", 27184.0], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", 26234.0], ["volta_sgemm_128x64_nt", 23737.0], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", 21753.0], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", 14259.0], ["volta_sgemm_128x64_nn", 11407.0], ["volta_scudnn_128x64_stridedB_interior_nn_v1", 10904.0], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 8816.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 8346.0], ["volta_scudnn_128x64_relu_interior_nn_v1", 7210.0], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", 7058.0], ["volta_scudnn_128x128_stridedB_interior_nn_v1", 5717.0], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", 5482.0], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 5341.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 5298.0], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", 5250.0], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 4895.0], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", 4781.0], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 4765.0], ["volta_scudnn_128x128_stridedB_medium_nn_v1", 4312.0], ["volta_scudnn_128x64_relu_medium_nn_v1", 3829.0], ["volta_scudnn_128x128_stridedB_small_nn_v1", 3709.0], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 3533.0], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", 3532.0], ["volta_scudnn_128x64_relu_small_nn_v1", 3395.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", 2779.0], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", 2617.0], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 2602.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", 2572.0], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", 2449.0], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", 2283.0], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", 1699.0], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", 1341.0], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", 1306.0], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 848.0], ["volta_scudnn_128x64_stridedB_small_nn_v1", 666.0], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", 330.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", 325.0], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", 256.0], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", 198.0], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", 174.0], ["volta_sgemm_64x32_sliced1x4_nn", 166.0], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", 162.0], ["volta_sgemm_64x32_sliced1x4_tn", 145.0], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", 135.0], ["volta_sgemm_128x32_nt", 117.0], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", 90.0], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", 64.0], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", 60.0], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", 48.0], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", 35.0], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", 33.0], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", 20.0], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", 12.0]]}}
{"steps": {"columns": [{"type": "string", "name": "Step"}, {"type": "number", "name": "Kernel"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memcpy"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Communication"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memset"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Runtime"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "DataLoader"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "CPU Exec"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Other"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}], "rows": [["5", 101214, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 118439us<br><b>Kernel: 101214us</b><br>Percentage: 85.46%</div>", 3344, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 118439us<br><b>Memcpy: 3344us</b><br>Percentage: 2.82%</div>", 54, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 118439us<br><b>Memset: 54us</b><br>Percentage: 0.05%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 118439us<br><b>Communication: 0us</b><br>Percentage: 0.0%</div>", 2996, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 118439us<br><b>Runtime: 2996us</b><br>Percentage: 2.53%</div>", 3, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 118439us<br><b>DataLoader: 3us</b><br>Percentage: 0.0%</div>", 10088, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 118439us<br><b>CPU Exec: 10088us</b><br>Percentage: 8.52%</div>", 740, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 118439us<br><b>Other: 740us</b><br>Percentage: 0.62%</div>"], ["6", 101100, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 116360us<br><b>Kernel: 101100us</b><br>Percentage: 86.89%</div>", 3239, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 116360us<br><b>Memcpy: 3239us</b><br>Percentage: 2.78%</div>", 54, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 116360us<br><b>Memset: 54us</b><br>Percentage: 0.05%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 116360us<br><b>Communication: 0us</b><br>Percentage: 0.0%</div>", 2811, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 116360us<br><b>Runtime: 2811us</b><br>Percentage: 2.42%</div>", 15, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 116360us<br><b>DataLoader: 15us</b><br>Percentage: 0.01%</div>", 8391, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 116360us<br><b>CPU Exec: 8391us</b><br>Percentage: 7.21%</div>", 750, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 116360us<br><b>Other: 750us</b><br>Percentage: 0.64%</div>"], ["7", 101159, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 114583us<br><b>Kernel: 101159us</b><br>Percentage: 88.28%</div>", 3218, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 114583us<br><b>Memcpy: 3218us</b><br>Percentage: 2.81%</div>", 54, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 114583us<br><b>Memset: 54us</b><br>Percentage: 0.05%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 114583us<br><b>Communication: 0us</b><br>Percentage: 0.0%</div>", 2584, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 114583us<br><b>Runtime: 2584us</b><br>Percentage: 2.26%</div>", 23, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 114583us<br><b>DataLoader: 23us</b><br>Percentage: 0.02%</div>", 6908, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 114583us<br><b>CPU Exec: 6908us</b><br>Percentage: 6.03%</div>", 637, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 114583us<br><b>Other: 637us</b><br>Percentage: 0.56%</div>"], ["8", 101317, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 119884us<br><b>Kernel: 101317us</b><br>Percentage: 84.51%</div>", 3251, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 119884us<br><b>Memcpy: 3251us</b><br>Percentage: 2.71%</div>", 54, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 119884us<br><b>Memset: 54us</b><br>Percentage: 0.05%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 119884us<br><b>Communication: 0us</b><br>Percentage: 0.0%</div>", 2929, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 119884us<br><b>Runtime: 2929us</b><br>Percentage: 2.44%</div>", 13, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 119884us<br><b>DataLoader: 13us</b><br>Percentage: 0.01%</div>", 11610, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 119884us<br><b>CPU Exec: 11610us</b><br>Percentage: 9.68%</div>", 710, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 119884us<br><b>Other: 710us</b><br>Percentage: 0.59%</div>"], ["9", 101022, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 117173us<br><b>Kernel: 101022us</b><br>Percentage: 86.22%</div>", 3308, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 117173us<br><b>Memcpy: 3308us</b><br>Percentage: 2.82%</div>", 54, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 117173us<br><b>Memset: 54us</b><br>Percentage: 0.05%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 117173us<br><b>Communication: 0us</b><br>Percentage: 0.0%</div>", 3002, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 117173us<br><b>Runtime: 3002us</b><br>Percentage: 2.56%</div>", 16, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 117173us<br><b>DataLoader: 16us</b><br>Percentage: 0.01%</div>", 9021, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 117173us<br><b>CPU Exec: 9021us</b><br>Percentage: 7.7%</div>", 750, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 117173us<br><b>Other: 750us</b><br>Percentage: 0.64%</div>"], ["10", 101236, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 139414us<br><b>Kernel: 101236us</b><br>Percentage: 72.62%</div>", 3361, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 139414us<br><b>Memcpy: 3361us</b><br>Percentage: 2.41%</div>", 54, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 139414us<br><b>Memset: 54us</b><br>Percentage: 0.04%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 139414us<br><b>Communication: 0us</b><br>Percentage: 0.0%</div>", 2192, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 139414us<br><b>Runtime: 2192us</b><br>Percentage: 1.57%</div>", 0, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 139414us<br><b>DataLoader: 0us</b><br>Percentage: 0.0%</div>", 8527, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 139414us<br><b>CPU Exec: 8527us</b><br>Percentage: 6.12%</div>", 24044, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 139414us<br><b>Other: 24044us</b><br>Percentage: 17.25%</div>"]]}, "performance": [{"name": "Average Step Time", "description": "", "value": 120976, "extra": 100, "children": [{"name": "Kernel", "description": "", "value": 101175, "extra": 83.63}, {"name": "Memcpy", "description": "", "value": 3287, "extra": 2.72}, {"name": "Memset", "description": "", "value": 54, "extra": 0.04}, {"name": "Communication", "description": "", "value": 0, "extra": 0.0}, {"name": "Runtime", "description": "", "value": 2752, "extra": 2.28}, {"name": "DataLoader", "description": "", "value": 12, "extra": 0.01}, {"name": "CPU Exec", "description": "", "value": 9091, "extra": 7.51}, {"name": "Other", "description": "", "value": 4605, "extra": 3.81}]}], "recommendations": "<ul><li>N/A</li></ul>", "environments": [{"title": "Number of Worker(s)", "value": "1"}, {"title": "Device Type", "value": "GPU"}, {"title": "GPU Utilization of GPU0", "value": "83.63 %"}]}
{"device_total_time": {"title": "Device Total Time (us)", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward", 288342], ["CudnnConvolutionBackward", 288342], ["aten::cudnn_convolution_backward_weight", 151977], ["aten::cudnn_convolution_backward_input", 136365], ["aten::cudnn_convolution", 134544], ["aten::_convolution", 134544], ["aten::convolution", 134544], ["aten::conv2d", 134544], ["aten::cudnn_batch_norm_backward", 56960], ["CudnnBatchNormBackward", 56960], ["aten::cudnn_batch_norm", 33334], ["aten::_batch_norm_impl_index", 33334], ["aten::batch_norm", 33334], ["aten::threshold_backward", 26280], ["ReluBackward1", 26280], ["aten::add_", 23354], ["aten::to", 19721], ["aten::copy_", 19721], ["aten::threshold_", 17770], ["aten::relu_", 17770], ["aten::max_pool2d_with_indices_backward", 5053], ["MaxPool2DWithIndicesBackward", 5053], ["torch::autograd::AccumulateGrad", 2918], ["aten::fill_", 2376], ["aten::mul_", 2376], ["aten::zero_", 2370], ["aten::max_pool2d_with_indices", 1341], ["aten::max_pool2d", 1341], ["aten::zeros_like", 948], ["aten::add", 327], ["aten::mm", 288], ["AddmmBackward", 288], ["aten::mean", 258], ["aten::adaptive_avg_pool2d", 258], ["aten::addmm", 204], ["aten::div", 161], ["MeanBackward1", 161], ["aten::_log_softmax_backward_data", 63], ["LogSoftmaxBackward", 63], ["aten::_log_softmax", 60], ["aten::log_softmax", 60], ["aten::nll_loss_forward", 21], ["aten::nll_loss", 21], ["aten::nll_loss_backward", 19], ["NllLossBackward", 19], ["aten::ones_like", 6]]}, "device_self_time": {"title": "Device Self Time (us)", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward_weight", 151977], ["aten::cudnn_convolution_backward_input", 136365], ["aten::cudnn_convolution", 134544], ["aten::cudnn_batch_norm_backward", 56960], ["aten::cudnn_batch_norm", 33334], ["aten::threshold_backward", 26280], ["aten::add_", 23354], ["aten::copy_", 19721], ["aten::threshold_", 17770], ["aten::max_pool2d_with_indices_backward", 4105], ["aten::fill_", 2376], ["aten::mul_", 2376], ["aten::max_pool2d_with_indices", 1341], ["aten::add", 327], ["aten::mm", 288], ["aten::mean", 258], ["aten::addmm", 204], ["aten::div", 161], ["aten::_log_softmax_backward_data", 63], ["aten::_log_softmax", 60], ["aten::nll_loss_forward", 21], ["aten::nll_loss_backward", 19]]}, "host_total_time": {"title": "Host Total Time (us)", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::to", 95877], ["aten::copy_", 95330], ["CudnnConvolutionBackward", 89870], ["aten::add_", 88364], ["aten::cudnn_convolution_backward", 85929], ["aten::conv2d", 60800], ["aten::convolution", 56995], ["aten::batch_norm", 53643], ["aten::_convolution", 53318], ["aten::_batch_norm_impl_index", 50036], ["aten::cudnn_convolution", 48860], ["aten::cudnn_batch_norm", 46680], ["torch::autograd::AccumulateGrad", 43241], ["aten::cudnn_convolution_backward_input", 39025], ["aten::cudnn_convolution_backward_weight", 37464], ["CudnnBatchNormBackward", 34153], ["aten::mul_", 32585], ["aten::zero_", 32441], ["aten::cudnn_batch_norm_backward", 29705], ["aten::empty", 29598], ["aten::fill_", 19488], ["aten::relu_", 16391], ["ReluBackward1", 15546], ["aten::add", 14077], ["aten::threshold_backward", 13019], ["aten::threshold_", 8921], ["aten::empty_like", 6343], ["aten::resize_", 3854], ["aten::view", 2824], ["AddmmBackward", 1508], ["aten::addmm", 1219], ["aten::mm", 857], ["MaxPool2DWithIndicesBackward", 779], ["NllLossBackward", 737], ["aten::t", 714], ["aten::max_pool2d", 709], ["aten::max_pool2d_with_indices_backward", 699], ["aten::zeros", 625], ["aten::max_pool2d_with_indices", 622], ["MeanBackward1", 615], ["aten::nll_loss_backward", 604], ["aten::adaptive_avg_pool2d", 530], ["aten::log_softmax", 513], ["aten::nll_loss", 504], ["LogSoftmaxBackward", 454], ["aten::mean", 449], ["aten::_log_softmax", 434], ["aten::nll_loss_forward", 430], ["aten::div", 426], ["aten::_log_softmax_backward_data", 383], ["aten::ones_like", 381], ["AddBackward0", 337], ["aten::transpose", 331], ["aten::zeros_like", 331], ["aten::empty_strided", 319], ["aten::reshape", 223], ["aten::flatten", 187], ["TBackward", 174], ["aten::expand", 150], ["ViewBackward", 130], ["aten::as_strided", 128], ["aten::set_", 118], ["aten::detach_", 95], ["aten::resize_as_", 60], ["aten::conj", 53], ["detach_", 32]]}, "host_self_time": {"title": "Host Self Time (us)", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::add_", 55210], ["aten::cudnn_convolution", 34694], ["aten::empty", 29598], ["aten::cudnn_batch_norm", 26054], ["aten::cudnn_convolution_backward_input", 25909], ["aten::cudnn_convolution_backward_weight", 22068], ["aten::mul_", 20698], ["aten::cudnn_batch_norm_backward", 17176], ["aten::zero_", 13103], ["torch::autograd::AccumulateGrad", 12619], ["aten::cudnn_convolution_backward", 9440], ["aten::add", 8964], ["aten::fill_", 8708], ["aten::relu_", 7470], ["aten::threshold_backward", 7358], ["aten::_convolution", 4458], ["CudnnBatchNormBackward", 4448], ["aten::threshold_", 4042], ["CudnnConvolutionBackward", 3941], ["aten::resize_", 3854], ["aten::conv2d", 3805], ["aten::convolution", 3677], ["aten::batch_norm", 3607], ["aten::empty_like", 3452], ["aten::_batch_norm_impl_index", 3356], ["aten::view", 2824], ["ReluBackward1", 2527], ["aten::addmm", 690], ["aten::zeros", 465], ["aten::mm", 460], ["aten::copy_", 426], ["aten::t", 383], ["aten::max_pool2d_with_indices", 363], ["AddBackward0", 337], ["aten::empty_strided", 319], ["aten::nll_loss_forward", 317], ["aten::to", 300], ["aten::mean", 283], ["aten::nll_loss_backward", 279], ["aten::div", 265], ["aten::transpose", 233], ["aten::_log_softmax", 224], ["aten::max_pool2d_with_indices_backward", 223], ["AddmmBackward", 213], ["aten::_log_softmax_backward_data", 160], ["NllLossBackward", 133], ["aten::as_strided", 128], ["aten::expand", 120], ["aten::set_", 118], ["aten::max_pool2d", 87], ["MeanBackward1", 87], ["aten::ones_like", 85], ["aten::adaptive_avg_pool2d", 81], ["MaxPool2DWithIndicesBackward", 80], ["aten::log_softmax", 79], ["aten::nll_loss", 74], ["LogSoftmaxBackward", 71], ["aten::reshape", 70], ["aten::detach_", 63], ["aten::flatten", 59], ["aten::zeros_like", 54], ["aten::conj", 53], ["aten::resize_as_", 49], ["TBackward", 43], ["ViewBackward", 35], ["detach_", 32]]}}
[{"name": "aten::cudnn_convolution_backward_weight", "calls": 318, "device_self_duration": 151977, "device_total_duration": 151977, "host_self_duration": 22068, "host_total_duration": 37464, "has_call_stack": false}, {"name": "aten::cudnn_convolution_backward_input", "calls": 312, "device_self_duration": 136365, "device_total_duration": 136365, "host_self_duration": 25909, "host_total_duration": 39025, "has_call_stack": false}, {"name": "aten::cudnn_convolution", "calls": 318, "device_self_duration": 134544, "device_total_duration": 134544, "host_self_duration": 34694, "host_total_duration": 48860, "has_call_stack": false}, {"name": "aten::cudnn_batch_norm_backward", "calls": 318, "device_self_duration": 56960, "device_total_duration": 56960, "host_self_duration": 17176, "host_total_duration": 29705, "has_call_stack": false}, {"name": "aten::cudnn_batch_norm", "calls": 318, "device_self_duration": 33334, "device_total_duration": 33334, "host_self_duration": 26054, "host_total_duration": 46680, "has_call_stack": false}, {"name": "aten::threshold_backward", "calls": 294, "device_self_duration": 26280, "device_total_duration": 26280, "host_self_duration": 7358, "host_total_duration": 13019, "has_call_stack": false}, {"name": "aten::add_", "calls": 2994, "device_self_duration": 23354, "device_total_duration": 23354, "host_self_duration": 55210, "host_total_duration": 88364, "has_call_stack": false}, {"name": "aten::copy_", "calls": 12, "device_self_duration": 19721, "device_total_duration": 19721, "host_self_duration": 426, "host_total_duration": 95330, "has_call_stack": false}, {"name": "aten::threshold_", "calls": 294, "device_self_duration": 17770, "device_total_duration": 17770, "host_self_duration": 4042, "host_total_duration": 8921, "has_call_stack": false}, {"name": "aten::max_pool2d_with_indices_backward", "calls": 6, "device_self_duration": 4105, "device_total_duration": 5053, "host_self_duration": 223, "host_total_duration": 699, "has_call_stack": false}, {"name": "aten::fill_", "calls": 978, "device_self_duration": 2376, "device_total_duration": 2376, "host_self_duration": 8708, "host_total_duration": 19488, "has_call_stack": false}, {"name": "aten::mul_", "calls": 966, "device_self_duration": 2376, "device_total_duration": 2376, "host_self_duration": 20698, "host_total_duration": 32585, "has_call_stack": false}, {"name": "aten::max_pool2d_with_indices", "calls": 6, "device_self_duration": 1341, "device_total_duration": 1341, "host_self_duration": 363, "host_total_duration": 622, "has_call_stack": false}, {"name": "aten::add", "calls": 318, "device_self_duration": 327, "device_total_duration": 327, "host_self_duration": 8964, "host_total_duration": 14077, "has_call_stack": false}, {"name": "aten::mm", "calls": 12, "device_self_duration": 288, "device_total_duration": 288, "host_self_duration": 460, "host_total_duration": 857, "has_call_stack": false}, {"name": "aten::mean", "calls": 6, "device_self_duration": 258, "device_total_duration": 258, "host_self_duration": 283, "host_total_duration": 449, "has_call_stack": false}, {"name": "aten::addmm", "calls": 6, "device_self_duration": 204, "device_total_duration": 204, "host_self_duration": 690, "host_total_duration": 1219, "has_call_stack": false}, {"name": "aten::div", "calls": 6, "device_self_duration": 161, "device_total_duration": 161, "host_self_duration": 265, "host_total_duration": 426, "has_call_stack": false}, {"name": "aten::_log_softmax_backward_data", "calls": 6, "device_self_duration": 63, "device_total_duration": 63, "host_self_duration": 160, "host_total_duration": 383, "has_call_stack": false}, {"name": "aten::_log_softmax", "calls": 6, "device_self_duration": 60, "device_total_duration": 60, "host_self_duration": 224, "host_total_duration": 434, "has_call_stack": false}, {"name": "aten::nll_loss_forward", "calls": 6, "device_self_duration": 21, "device_total_duration": 21, "host_self_duration": 317, "host_total_duration": 430, "has_call_stack": false}, {"name": "aten::nll_loss_backward", "calls": 6, "device_self_duration": 19, "device_total_duration": 19, "host_self_duration": 279, "host_total_duration": 604, "has_call_stack": false}, {"name": "aten::empty", "calls": 5172, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 29598, "host_total_duration": 29598, "has_call_stack": false}, {"name": "aten::zero_", "calls": 996, "device_self_duration": 0, "device_total_duration": 2370, "host_self_duration": 13103, "host_total_duration": 32441, "has_call_stack": false}, {"name": "aten::zeros", "calls": 24, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 465, "host_total_duration": 625, "has_call_stack": false}, {"name": "aten::to", "calls": 30, "device_self_duration": 0, "device_total_duration": 19721, "host_self_duration": 300, "host_total_duration": 95877, "has_call_stack": false}, {"name": "detach_", "calls": 12, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 32, "host_total_duration": 32, "has_call_stack": false}, {"name": "aten::detach_", "calls": 12, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 63, "host_total_duration": 95, "has_call_stack": false}, {"name": "aten::set_", "calls": 12, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 118, "host_total_duration": 118, "has_call_stack": false}, {"name": "aten::empty_strided", "calls": 18, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 319, "host_total_duration": 319, "has_call_stack": false}, {"name": "aten::resize_", "calls": 1920, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 3854, "host_total_duration": 3854, "has_call_stack": false}, {"name": "aten::_convolution", "calls": 318, "device_self_duration": 0, "device_total_duration": 134544, "host_self_duration": 4458, "host_total_duration": 53318, "has_call_stack": false}, {"name": "aten::convolution", "calls": 318, "device_self_duration": 0, "device_total_duration": 134544, "host_self_duration": 3677, "host_total_duration": 56995, "has_call_stack": false}, {"name": "aten::conv2d", "calls": 318, "device_self_duration": 0, "device_total_duration": 134544, "host_self_duration": 3805, "host_total_duration": 60800, "has_call_stack": false}, {"name": "aten::empty_like", "calls": 342, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 3452, "host_total_duration": 6343, "has_call_stack": false}, {"name": "aten::view", "calls": 648, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 2824, "host_total_duration": 2824, "has_call_stack": false}, {"name": "aten::_batch_norm_impl_index", "calls": 318, "device_self_duration": 0, "device_total_duration": 33334, "host_self_duration": 3356, "host_total_duration": 50036, "has_call_stack": false}, {"name": "aten::batch_norm", "calls": 318, "device_self_duration": 0, "device_total_duration": 33334, "host_self_duration": 3607, "host_total_duration": 53643, "has_call_stack": false}, {"name": "aten::relu_", "calls": 294, "device_self_duration": 0, "device_total_duration": 17770, "host_self_duration": 7470, "host_total_duration": 16391, "has_call_stack": false}, {"name": "aten::max_pool2d", "calls": 6, "device_self_duration": 0, "device_total_duration": 1341, "host_self_duration": 87, "host_total_duration": 709, "has_call_stack": false}, {"name": "aten::adaptive_avg_pool2d", "calls": 6, "device_self_duration": 0, "device_total_duration": 258, "host_self_duration": 81, "host_total_duration": 530, "has_call_stack": false}, {"name": "aten::reshape", "calls": 12, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 70, "host_total_duration": 223, "has_call_stack": false}, {"name": "aten::flatten", "calls": 6, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 59, "host_total_duration": 187, "has_call_stack": false}, {"name": "aten::as_strided", "calls": 42, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 128, "host_total_duration": 128, "has_call_stack": false}, {"name": "aten::transpose", "calls": 30, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 233, "host_total_duration": 331, "has_call_stack": false}, {"name": "aten::t", "calls": 30, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 383, "host_total_duration": 714, "has_call_stack": false}, {"name": "aten::expand", "calls": 12, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 120, "host_total_duration": 150, "has_call_stack": false}, {"name": "aten::log_softmax", "calls": 6, "device_self_duration": 0, "device_total_duration": 60, "host_self_duration": 79, "host_total_duration": 513, "has_call_stack": false}, {"name": "aten::nll_loss", "calls": 6, "device_self_duration": 0, "device_total_duration": 21, "host_self_duration": 74, "host_total_duration": 504, "has_call_stack": false}, {"name": "aten::ones_like", "calls": 6, "device_self_duration": 0, "device_total_duration": 6, "host_self_duration": 85, "host_total_duration": 381, "has_call_stack": false}, {"name": "NllLossBackward", "calls": 6, "device_self_duration": 0, "device_total_duration": 19, "host_self_duration": 133, "host_total_duration": 737, "has_call_stack": false}, {"name": "LogSoftmaxBackward", "calls": 6, "device_self_duration": 0, "device_total_duration": 63, "host_self_duration": 71, "host_total_duration": 454, "has_call_stack": false}, {"name": "aten::conj", "calls": 12, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 53, "host_total_duration": 53, "has_call_stack": false}, {"name": "AddmmBackward", "calls": 6, "device_self_duration": 0, "device_total_duration": 288, "host_self_duration": 213, "host_total_duration": 1508, "has_call_stack": false}, {"name": "torch::autograd::AccumulateGrad", "calls": 966, "device_self_duration": 0, "device_total_duration": 2918, "host_self_duration": 12619, "host_total_duration": 43241, "has_call_stack": false}, {"name": "TBackward", "calls": 6, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 43, "host_total_duration": 174, "has_call_stack": false}, {"name": "ViewBackward", "calls": 6, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 35, "host_total_duration": 130, "has_call_stack": false}, {"name": "MeanBackward1", "calls": 6, "device_self_duration": 0, "device_total_duration": 161, "host_self_duration": 87, "host_total_duration": 615, "has_call_stack": false}, {"name": "ReluBackward1", "calls": 294, "device_self_duration": 0, "device_total_duration": 26280, "host_self_duration": 2527, "host_total_duration": 15546, "has_call_stack": false}, {"name": "AddBackward0", "calls": 96, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 337, "host_total_duration": 337, "has_call_stack": false}, {"name": "CudnnBatchNormBackward", "calls": 318, "device_self_duration": 0, "device_total_duration": 56960, "host_self_duration": 4448, "host_total_duration": 34153, "has_call_stack": false}, {"name": "aten::cudnn_convolution_backward", "calls": 318, "device_self_duration": 0, "device_total_duration": 288342, "host_self_duration": 9440, "host_total_duration": 85929, "has_call_stack": false}, {"name": "CudnnConvolutionBackward", "calls": 318, "device_self_duration": 0, "device_total_duration": 288342, "host_self_duration": 3941, "host_total_duration": 89870, "has_call_stack": false}, {"name": "aten::zeros_like", "calls": 6, "device_self_duration": 0, "device_total_duration": 948, "host_self_duration": 54, "host_total_duration": 331, "has_call_stack": false}, {"name": "aten::resize_as_", "calls": 6, "device_self_duration": 0, "device_total_duration": 0, "host_self_duration": 49, "host_total_duration": 60, "has_call_stack": false}, {"name": "MaxPool2DWithIndicesBackward", "calls": 6, "device_self_duration": 0, "device_total_duration": 5053, "host_self_duration": 80, "host_total_duration": 779, "has_call_stack": false}]
{"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Total Duration (us)"}, {"type": "number", "name": "Mean Duration (us)"}, {"type": "number", "name": "Max Duration (us)"}, {"type": "number", "name": "Min Duration (us)"}], "rows": [["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", 178, 90214, 507, 1092, 154], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 179, 85427, 477, 814, 381], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", 292, 62347, 214, 802, 43], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", 613, 47476, 77, 364, 6], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", 3506, 41486, 12, 364, 1], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 84, 36210, 431, 753, 384], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 66, 32761, 496, 854, 362], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", 150, 26289, 175, 433, 50], ["volta_sgemm_128x64_nt", 126, 23803, 189, 205, 156], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", 49, 22477, 459, 705, 329], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 21, 18728, 892, 913, 881], ["volta_sgemm_128x64_nn", 78, 14530, 186, 207, 157], ["volta_scudnn_128x64_stridedB_interior_nn_v1", 35, 11515, 329, 528, 260], ["volta_scudnn_128x64_relu_interior_nn_v1", 30, 10280, 343, 530, 295], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 14, 8372, 598, 993, 207], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", 21, 7728, 368, 377, 365], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", 141, 7213, 51, 115, 20], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 141, 7133, 51, 143, 17], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", 168, 7045, 42, 87, 14], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", 178, 5920, 33, 158, 6], ["volta_scudnn_128x128_stridedB_interior_nn_v1", 21, 5763, 274, 294, 269], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 12, 5352, 446, 449, 443], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 7, 5335, 762, 781, 744], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 6, 4882, 814, 817, 811], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", 7, 4795, 685, 690, 683], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", 7, 4662, 666, 669, 658], ["volta_scudnn_128x128_stridedB_medium_nn_v1", 14, 4373, 312, 327, 297], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 6, 4023, 670, 676, 663], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", 6, 4007, 668, 672, 664], ["volta_scudnn_128x64_relu_medium_nn_v1", 6, 3850, 642, 644, 638], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", 6, 3731, 622, 672, 571], ["volta_scudnn_128x128_stridedB_small_nn_v1", 7, 3726, 532, 542, 526], ["volta_scudnn_128x64_relu_small_nn_v1", 12, 3427, 286, 295, 272], ["volta_scudnn_128x128_relu_interior_nn_v1", 6, 3340, 557, 562, 551], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", 1127, 2771, 2, 24, 1], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", 141, 2699, 19, 66, 3], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 63, 2540, 40, 60, 20], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", 979, 2534, 3, 158, 0], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", 63, 2479, 39, 60, 18], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", 54, 2313, 43, 74, 19], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", 6, 1341, 224, 224, 223], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", 63, 1320, 21, 65, 4], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 6, 864, 144, 147, 142], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", 6, 601, 100, 101, 99], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", 137, 352, 3, 6, 2], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", 318, 327, 1, 2, 1], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", 6, 258, 43, 43, 43], ["volta_sgemm_64x32_sliced1x4_nn", 6, 161, 27, 27, 26], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", 6, 161, 27, 27, 26], ["volta_sgemm_64x32_sliced1x4_tn", 6, 144, 24, 24, 24], ["volta_sgemm_128x32_nt", 6, 115, 19, 20, 19], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", 62, 87, 1, 2, 1], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", 77, 85, 1, 2, 1], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", 21, 84, 4, 4, 4], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", 62, 75, 1, 2, 1], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", 6, 63, 10, 11, 10], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", 6, 60, 10, 10, 10], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", 6, 48, 8, 8, 8], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", 12, 36, 3, 4, 2], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", 6, 36, 6, 6, 6], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", 6, 21, 4, 4, 3], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", 6, 13, 2, 3, 2]]}}
{"total": {"columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", 90214.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 85427.0], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", 62347.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", 47476.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", 41486.0], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 36210.0], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 32761.0], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", 26289.0], ["volta_sgemm_128x64_nt", 23803.0], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", 22477.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 18728.0], ["volta_sgemm_128x64_nn", 14530.0], ["volta_scudnn_128x64_stridedB_interior_nn_v1", 11515.0], ["volta_scudnn_128x64_relu_interior_nn_v1", 10280.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 8372.0], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", 7728.0], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", 7213.0], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 7133.0], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", 7045.0], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", 5920.0], ["volta_scudnn_128x128_stridedB_interior_nn_v1", 5763.0], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 5352.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 5335.0], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 4882.0], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", 4795.0], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", 4662.0], ["volta_scudnn_128x128_stridedB_medium_nn_v1", 4373.0], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 4023.0], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", 4007.0], ["volta_scudnn_128x64_relu_medium_nn_v1", 3850.0], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", 3731.0], ["volta_scudnn_128x128_stridedB_small_nn_v1", 3726.0], ["volta_scudnn_128x64_relu_small_nn_v1", 3427.0], ["volta_scudnn_128x128_relu_interior_nn_v1", 3340.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", 2771.0], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", 2699.0], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 2540.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", 2534.0], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", 2479.0], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", 2313.0], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", 1341.0], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", 1320.0], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 864.0], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", 601.0], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", 352.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", 327.0], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", 258.0], ["volta_sgemm_64x32_sliced1x4_nn", 161.0], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", 161.0], ["volta_sgemm_64x32_sliced1x4_tn", 144.0], ["volta_sgemm_128x32_nt", 115.0], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", 87.0], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", 85.0], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", 84.0], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", 75.0], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", 63.0], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", 60.0], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", 48.0], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", 36.0], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", 36.0], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", 21.0], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", 13.0]]}}
